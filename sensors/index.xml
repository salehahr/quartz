<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sensors on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/sensors/</link><description>Recent content in Sensors on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Fri, 23 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://salehahr.github.io/zettelkasten/sensors/index.xml" rel="self" type="application/rss+xml"/><item><title>IMU</title><link>https://salehahr.github.io/zettelkasten/sensors/imu/</link><pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/imu/</guid><description>Source: Mur-Artal 2017 measures acceleration (from accelerometer) and angular velocity (from gyrometer) of sensor at regular intervals measurements are affected by sensor noise accelerometer bias gyrometer bias accelerometer is further affected by gravity &amp;ndash;&amp;gt; need to subtract effect of gravity</description></item><item><title>Sensors (absolute measurements) for measuring absolute POSE</title><link>https://salehahr.github.io/zettelkasten/sensors/sensors-absolute-pose/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/sensors-absolute-pose/</guid><description>Source: Wikipedia Lokalisierung GPS (only for outdoors) Innenraumsensorik Lidar, Ultra Wide Band (UWB), Wireless Fidelity, etc ( wu-2018 ) Compared to these, cameras are flexible and low-cost ( wu-2018 ) (are also passive sensors) ( cometlabs ) Radiobaken</description></item><item><title>Visual sensors for localisation</title><link>https://salehahr.github.io/zettelkasten/sensors/visual-sensors-for-localisation/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/visual-sensors-for-localisation/</guid><description>Source: Wikipedia Visual odometry Process of determining robot POSE by analysing the associated camera images Use sequential camera image to estimate the distance travelled Applications: robotics, computer vision
Source: Cometlabs Types
Monocular cameras Stereo cameras RGB-D cameras Provide rich visual information, but for that, higher computational cost
Source: SLAM for Dummies stereo or triclops sytem to measure distance [+] possibly more intuitive (bc humans use vision), more info.</description></item><item><title>Laser scanners</title><link>https://salehahr.github.io/zettelkasten/sensors/laser-scanners/</link><pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/laser-scanners/</guid><description>Source: SLAM for Dummies Commonly used [+] Precise, efficient, not much processing work necessary [-] Expensive, bad readings with certain surfaces, bad for underwater applications</description></item><item><title>Monocular cameras</title><link>https://salehahr.github.io/zettelkasten/sensors/monocular-cameras/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/monocular-cameras/</guid><description>Source: Cometlabs + Simpler hardware implementation + Smaller and cheapter systems - need complexer algos and software because of lack of direct depth information from a 2D image How is the shape of the map generated? Integrating measurements in the chain of frames over time Use triangulation method As well as camera motion, if camera isn&amp;rsquo;t stationary Depths of points are not oberved directly (s.</description></item><item><title>Position acquisition (relative vs. absolute)</title><link>https://salehahr.github.io/zettelkasten/sensors/position-acquisition/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/position-acquisition/</guid><description>See also: SLAM hardware Source: Cometlabs relative (interoceptive sensors) odometry absolute (exteroceptive sensors) can be used alongside relative measurement sensors in order to correct odometry drift s. major sensor types in SLAM (absolute measurements) incl. visual sensors Beacons direct measurement instead of integrating, therefore error in position does not grow unbounded e.g. laser ranger finders, wifi (collect signal strength across field), GPS (bad for indoors) Lidar, Ultra Wide Band (UWB), Wireless Fidelity, etc [ Wu ] Compared to these, cameras are flexible and low-cost [ Wu ] (are also passive sensors) [ Cometlabs ]</description></item><item><title>RGB-D cameras</title><link>https://salehahr.github.io/zettelkasten/sensors/rgb-d-cameras/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/rgb-d-cameras/</guid><description>Source: Cometlabs Provide depth information directly Employed by most of the SLAM systems Generate 3D images through structured light or time of flight technology Structured light camera projects a known pattern onto objects Perceives deformation of pattern by an infrared camera This lets depth and surface information of the objects be calculated Time of flight ToF of a light signal between camera and objects is measured &amp;ndash;&amp;gt; from this, depth is obtained Structured light sensors are sensitive to illumination &amp;ndash; not applicable in direct sunlight Limitations Range data for semi-transparent or highly reflective surfaces are not reliable Limited effective range</description></item><item><title>Sensors (absolute measurements) for measuring distance to landmarks</title><link>https://salehahr.github.io/zettelkasten/sensors/sensors-absolute/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/sensors-absolute/</guid><description>&amp;laquo;&amp;laquo;&amp;laquo;&amp;lt; HEAD:content/studienarbeit/sensors-absolute-measurements-for-measuring-distance-to-landmarks.md Parents: SLAM Index , slam-hardware Backlinks: Position acquisition Parents: slam-hardware content:content/sensors/sensors-absolute.md
Source: Cometlabs Acoustic (Time of Flight) ToF technique Surfaces need to have good acoustic reflection Lack the ability to use surface properties for localisation examples Sonar Ultrasonic, ultrasound Laser rangerfinders ToF and phase-shift techniques Lack the ability to use surface properties for localisation e.</description></item><item><title>Stereo cameras</title><link>https://salehahr.github.io/zettelkasten/sensors/stereo-cameras/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/stereo-cameras/</guid><description>Source: Cometlabs two cameras separated by a fixed distance (baseline) observations of the position of the same 3D point in both cameras allows depth to be calculated through triangulation (like humans do) depth measurement limited by baseline and resolution generally, wider baseline &amp;ndash;&amp;gt; better depth estimate (but occupies more physical space) s. also RGB-D cameras</description></item><item><title>SLAM hardware</title><link>https://salehahr.github.io/zettelkasten/sensors/slam-hardware/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/slam-hardware/</guid><description>See also: Position acquisition (relative vs. absolute) Source: SLAM for Dummies Robot parameters to consider Ease of use Odometry performance: how well the robot can estimate its own position, just from the rotation of the wheels Max errors: 2cm per meter moved, 2deg per 45deg turned Bad odometry &amp;ndash;&amp;gt; bad estimation of current position &amp;ndash;&amp;gt; hard to implement SLAM Range measurement device options Source: Wikipedia Lokalisierung Categories of sensors for localisation Measuring own movement [rel] Odometry sensors Compass Measuring distance to landmarks [abs] Measuring absolute POSE [abs]</description></item></channel></rss>