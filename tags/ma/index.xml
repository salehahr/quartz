<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>-ma on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/ma/</link><description>Recent content in -ma on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Wed, 01 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://salehahr.github.io/zettelkasten/tags/ma/index.xml" rel="self" type="application/rss+xml"/><item><title>2021-12-07</title><link>https://salehahr.github.io/zettelkasten/unlisted/2021-12-07/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/2021-12-07/</guid><description>Agenda MA Model now trains till end of epoch with model.fit().
Fix: use dataset.as_numpy_iterator().tolist() instead of dataset Current problem: losses are NaN, resulting predicted matrices are NaN
Still looking into it, but according to this thread , the cross entropy loss might be [one of] the cause[s]. HiWi Kugel ist fertig
GUI mit Beispielberechnung im separaten Thread ist fertig
for follow up: how to best to integrate with your simulations or general rendering tasks discussion of features (two pane view is probably unnecessary) etc.</description></item><item><title>2021-11-30</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-30/</link><pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-30/</guid><description>Agenda HiWi New: light position = camera centre MA Currently: must debug DataGenerator: training stops 1-3 batches before end! To do (from last week) 2021-11-23 HiWi Make light follow camera rotation Enable camera movement parallel to an ongoing rendering calculation (s. example with the sphere to cow rendering) Weihnachtskugel malen MA Train model skeletonised -&amp;gt; node attributes using existing data Debug DataGenerator Preliminaries Data augmentation - debug Data generation Watch more videos and trim away bad sections Adjust filter parameters so that more structures are visible Training data generation up to 3k w/o data augmentation Outcomes Possible outcomes for later: Comparing brute force method (input-output method) to function-/theory-based method (evtl mit PyTorch Funktionen, da muessen die Funktionen ableitbar sein) Try ReLU activation instead of sigmoid Notes World and camera coordinate systems in PyTorch3D Blasenmuster Fake Real</description></item><item><title>convex-problems</title><link>https://salehahr.github.io/zettelkasten/ma/convex-problems/</link><pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/convex-problems/</guid><description>Source: google-ml-course A convex function is shaped like this with respect to its parameters:
Convex problems only have one minimum (where the gradient is zero) &amp;ndash;&amp;gt; global minimum.</description></item><item><title>differentiable-rendering</title><link>https://salehahr.github.io/zettelkasten/ma/differentiable-rendering/</link><pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/differentiable-rendering/</guid><description>Source: https://pytorch3d.org/docs/renderer
&amp;ldquo;Differentiable rendering is a relatively new and exciting research area in computer vision, bridging the gap between 2D and 3D by allowing 2D image pixels to be related back to 3D properties of a scene.&amp;rdquo;</description></item><item><title>2021-11-16</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-16-static/</link><pubDate>Tue, 16 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-16-static/</guid><description>See also: 2021-11-16-outcomes Agenda Notes MA Scrapped translations as a data augmentation option Implemented function to sort nodes (left to right, up to down) before graph creation, thus ensuring that the adjacency matrix uses sorted node positions Created test suites which use a random photo from the existing dataset [training data] Testing suite in TestGraph (check if node positions are sorted, check if adj matrix matches photo) [tfgraph] Testing suite TestDataGeneration for testing data augmentation, s.</description></item><item><title>2021-11-23</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-23/</link><pubDate>Tue, 16 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-23/</guid><description>Agenda Notes MA Function for classifying between end nodes and border (invalid) nodes
Checks if node coordinates are in border zone
Border: 2px wide Helper node (green) -&amp;gt; reclassified to crossing node (blue) Up till now, saved border nodes in graph with the attribute NodeType.BORDER = 0 &amp;ndash;&amp;gt; change to another value to avoid mixup with the black pixels! Sample training data Data augmentation not yet working as desired, s.</description></item><item><title>2021-11-16-sample-augmented-data</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-16-sample-augmented-data/</link><pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-16-sample-augmented-data/</guid><description>Parent: 2021-11-16-static Sample input Augmented Input Filtered Skeletonised Node positions</description></item><item><title>2021-11-09</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-09/</link><pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-09/</guid><description>Agenda To-dos Ongoing Training data generation (up to 3k), including adjacency matrix Figure out model checkpoints &amp;ndash; still don&amp;rsquo;t understand Adjust model &amp;ndash; add more output channels Start HiWi (Pytorch 3D + PyQT GUI) by the end of the week New Model summary &amp;ndash; ca. 30M parameters Make new training data for 256px images (two folders: 256px, 512px) Implement data augmentation Rotations, translation, flip ok Schwierig oder nicht gut machbar: blurring, stretching, zoom U-Net DataGenerator, so far without augmentation Based on the class UNet in 03_CNN &amp;ndash; modifications: Branched outputs (to apply different losses/activation functions) Filtered output: linear activation, MSE loss Skeletonised output: sigmoid activation, binary crossentropy loss Alternative: final conv2D layer with 4 filters?</description></item><item><title>2021-11-03</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-03/</link><pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-03/</guid><description>To-do Old Generate up to 3k training photos [Hiwi] combine Peter&amp;rsquo;s existing PyQT GUI with PyTorch 3D to enable changing the camera view using mouse read Jupyter notebook tutorial go through PyQT stuff New Resize images to be smaller, squared, a square of two, e.g. 512 x 512 px To avoid unnecessary padding in the model Avoids the need for resizing within the model Note: if do end up using tf.</description></item><item><title>2021-11-02</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-02/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-11/2021-11-02/</guid><description>Agenda To clarify Training data Zugang zum Rechner Tuebingen Hiwi Training data Did a parameter study for B-COSFIRE filter parameters Automated some functions: naming convention, trimming according to video_data.py Some training data GRK021, GRK008 Goal: ca. 3,000 photos, apply transformations to these to get more training data ~10,000 Questions Which videos are already &amp;lsquo;done&amp;rsquo;, which are more important, in what order to process? &amp;ndash; doesn&amp;rsquo;t matter which, as long as I know which videos I took them from Do the images have to be squares?</description></item><item><title>2021-10-15</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-10/2021-10-15/</link><pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-10/2021-10-15/</guid><description>2021-10-15 Vorstellung Overall localisation project
Part that deals with localisation and mapping (graph stuff) Part that deals with deformation &amp;ndash; using Pytorch 3D Pytorch 3D 3D ground truth models are expensive Idea: generate 3D models (mesh) from 2D data (graph as a texture) Localisation using graphs Deformation problem: end nodes can appear to change position based on light conditions, bifurcation nodes are not affected Use neural network to extract adjacency matrix in real time One problem: Extraction of adjacency matrix is not robust to changes in matrix dimension, therefore do zero padding (as a partial solution to the problem) Idea First NN to extract node positions, node attributes such as polynomial degree, coefficients, etc number of connections Second NN to extract adjacency matrix between two nodes only (prerequisite: node positions already known, number of connections already known) Threading &amp;ndash; a thread can be terminated once the number of adjacencies has been found corresponding to the number of connections</description></item><item><title>2021-10-26</title><link>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-10/2021-10-26/</link><pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/minutes/2021-10/2021-10-26/</guid><description>2021-10-26 Kick-off meeting Tasks Read Regine&amp;rsquo;s documentation, SA thesis Generate training data with ground truth (labels) using Regine&amp;rsquo;s code Trim videos to show only relevant sections (where blood vessels are visible) &amp;mdash; (differentiating the situations to be implemented in other work) &amp;mdash; creating function in Python to trim Framework that runs all the functions in one go Notes Meetings Tuesday 10 a.m. Previous work by Regine: not real time &amp;ndash;&amp;gt; achieve real time capability by using Unet Existing code does: Filter colour photo to black and white Skeletonises the photo Extracts node position from the photo Extracts node attributes NN input: 256x256x3 photo NN output: 256x256xn, with n channels Channel 1: filtered photo Channel 2: skeletonised photo Channel 3: node position Channel 4: polynomial degree Maybe skip Channel 1 (filtered photo) and go to output 2 (skeletonished photo) directly Channel 3 (node pos) to go to polynomial degree directly, because once a nonzero number is in the matrix, it indicates that a node exists at that position!</description></item><item><title>ma-minutes</title><link>https://salehahr.github.io/zettelkasten/unlisted/ma-minutes/</link><pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/unlisted/ma-minutes/</guid><description> 2021-10-15 2021-10-26 2021-11-02 2021-11-03 2021-11-09 2021-11-16-static 2021-11-16-outcomes 2021-11-23 2021-11-30 2021-12-07</description></item></channel></rss>