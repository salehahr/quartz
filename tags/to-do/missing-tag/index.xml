<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>to-do/missing-tag on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/to-do/missing-tag/</link><description>Recent content in to-do/missing-tag on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/to-do/missing-tag/index.xml" rel="self" type="application/rss+xml"/><item><title>Dynamic Bayesian Network formulation of SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/dynamic-bayesian-network-formulation-of-slam/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/dynamic-bayesian-network-formulation-of-slam/</guid><description>Source: Grisetti 2011 - Tutorial graph-based SLAM Dynamic Bayesian Network
Solution of full SLAM problem: Transition model: Observation model:  The observation model is usually multimodal: a single observation may result in multiple edges (in the spatial graph) Therefore, the Gaussian assumption does not hold</description></item><item><title>Tracking in VIORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</guid><description>Source: Mur-Artal 2017 VI-ORB Tracking in VIORB
Visual-inertial tracking at frame rate, instead of using an ad-hoc motion model as in the original ORB-SLAM Tracked states: [sensor pose (R, p), velocities v, biases b] Once the camera pose is predicted, map points are projected, then matches with existing features on the frame Then optimise the current frame j, depending on whether the map has just been updated the map is unchanged Here, the optimisation function for tracking (when map unchanged) is:</description></item></channel></rss>