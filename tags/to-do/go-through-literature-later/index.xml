<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>to-do/go-through-literature-later on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/to-do/go-through-literature-later/</link><description>Recent content in to-do/go-through-literature-later on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/to-do/go-through-literature-later/index.xml" rel="self" type="application/rss+xml"/><item><title>Data association in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/data-association-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/data-association-in-defslam/</guid><description>Source: Lamarca 2020 DefSLAM See also: Data association Goal: match keypoints in current frame (newly extracted) with map points (already in map/system) Use the active matching strategy proposed in [Agudo 2015]: “Simultaneous pose and non-rigid shape with particle dynamics,” Steps  ORB points (keypoints) are detected in current frame
Camera pose Tcw is predicted
using camera motion model camera motion model: function of past camera poses Predict where map points (existing in map) would be imaged, based on last estimated template i.</description></item><item><title>Non-rigid Surface from Motion</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm/</guid><description>Notes:
Original NRSFM paper?
https://www.cs.dartmouth.edu/~lorenzo/Papers/TorrHertzBreg-pami08.pdf A Phd thesis [Kumar] https://openresearch-repository.anu.edu.au/handle/1885/164278?mode=full Source: Kumar
The problem with dynamic or non-rigid scenes:
if we project a scene point into a camera image plane, there will be several possible 3D configurations! Allowing arbitrary deformations makes the 3D reconstruction an ill posed problem (underconstrained) &amp;ndash;&amp;gt; need to make additional assumptions about the object or scene (make more constraints)! Source: lamarca-2020 See also: nrsfm-in-defslam , sfm NRSfM (non-rigid structure from motion) batch processing of images to recover deformation computationally demanding — slower than SfT Orthographic NRSfM usually fails with very large deformations uses an orthographic camera projection/model (weak approximation to the perspective camera) — a limitation, as many vision-related applications have a significant perspective effect exploits spatial constraints temporal constraints spatiotemporal constraints usually ok for small deformations, but not for very large deformations Perspective NRSfM the perspective camera model is more accurate than the orthographic one also uses the isometry assumption (as in SfT methods), which has produced good results in NRSfM Parashar 2018 &amp;ldquo;Isometric NRSfM&amp;rdquo; [6] local method that handles occlusions and missing data well</description></item><item><title>Shape from Motion</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sft/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sft/</guid><description>Initial paper?: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010934https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010934
Goal reconstruct the surface of an object
reference 3D shape (template) of the object is available under a specific deformation constraint Source: lamarca-2020 SFT (shape from template) uses only a single image — faster than nrsfm lower computational cost must have a known 3D template (textured model) SfT methods require: 1 monocular image 1 textured shape at rest (template) &amp;ldquo;geometry&amp;rdquo; as the deformation model different definitions of the deformation model analytic, e.</description></item><item><title>(Mur-Artal 2017) VI-ORB</title><link>https://salehahr.github.io/zettelkasten/bibliography/mur-artal-2017-vi-orb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/mur-artal-2017-vi-orb/</guid><description>URL: http://ieeexplore.ieee.org/abstract/document/7817784
Authors: Mur-Artal, Tardós
Code: http://paperswithcode.com/paper/visual-inertial-monocular-slam-with-map-reuse
Results (video): http://www.youtube.com/watch?v=JXRCSovuxbA
Abstract current VI odometry approaches: drift accumulates due to lack of loop closure therefore there is a need for tightly-coupled VI-SLAM with loop closure and map reuse here: focus on monocular case, but applicable to other camera configurations builds on ORB-SLAM (from same author) IMU initialisation method (initialises: scale, gravity direction, velocities, gyroscope bias, accelerometer bias) depends on visual monocular initialisation (coupled initialisation) Other works: recent tightly-coupled VIO (both filtering- and optimisation-based) lack loop closure, so drift accumulates</description></item><item><title>Cadena 2016 Past, Present, and Future of SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</guid><description>Authors Cadena et al
Abstract
cited by 1.2k people &amp;ldquo;This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM&amp;rdquo; Recommended other works s. Works of possible interest Contents/Chapters Takeaway</description></item><item><title>Lamarca 2020 DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</guid><description>URL: http://arxiv.org/abs/1908.08918
Authors: Lamarca et al
Code: http://github.com/UZ-SLAMLab/DefSLAM
Results (video): http://www.youtube.com/watch?v=6mmhD2_t6Gs Summary First monocular SLAM for deformable environments in real-time Most other SLAM implementations assume rigidity Main techniques used (techniques for monocular non-rigid scenes): isometric shape from template ( SfT ) non-rigid structure from motion ( NRSfM ) Main principle: computation in two parallel threads (s. DefSLAM framework) Deformation tracking [front end] Deformation mapping [back end] The map from the mapping thread defines the shape-at-rest template used by deformation tracking Validation: compare with ORBSLAM (rigid) Assumes isometric deformation Future work: relocalisation (s.</description></item></channel></rss>