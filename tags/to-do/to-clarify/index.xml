<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>to-do/to-clarify on</title><link>https://salehahr.github.io/tags/to-do/to-clarify/</link><description>Recent content in to-do/to-clarify on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://salehahr.github.io/tags/to-do/to-clarify/index.xml" rel="self" type="application/rss+xml"/><item><title>Gibbs / Rodrigues parameter representation for rotations</title><link>https://salehahr.github.io/studienarbeit/gibbs-rodrigues-parameter-representation-for-rotations/</link><pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/gibbs-rodrigues-parameter-representation-for-rotations/</guid><description>Parent: Orientation parametrisations Backlinks: [50.5.1 Observation of the error state (filter correction)](50.5.1 observation of the error state (filter correction).md), 50.5.3-eskf-reset See also: Rotation error representation Source: Markley 2014 From unit quaternions : From Euler axis/angle : To unit quaternions :   Plane of the figure contains identity quaternion, origin The circle is a cross section of the quaternion sphere S^3 The upper horizontal axis is the 3D Gibbs vector hyperplane (tangent at the identity quaternion) [+] q and -q map to the same Gibbs vector, therefore there is a 1:1 mapping of rotations between quaternions and the Gibbs parameter [-] the Gibbs vector is infinite for 180 degree rotations (q.</description></item><item><title>50.7 ESKF update / Fusing IMU with complementary sensory data</title><link>https://salehahr.github.io/studienarbeit/50.7-eskf-update-fusing-imu-with-complementary-sensory-data/</link><pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/50.7-eskf-update-fusing-imu-with-complementary-sensory-data/</guid><description>Parent: [IMU index](imu index.md), 50.3 error-state-kalman-filter Source: Solà 2017 Quaternion kinematics for ESKF In the ESKF, the arrival of non-IMU sensor data triggers a correction stage. This correction makes the IMU biases observable , allows correct estimation of the biases The correction stage is three-fold:
observe the error state by way of filter correction &amp;lsquo;add&amp;rsquo; the observed errors to the nominal state to get the supposed &amp;lsquo;true&amp;rsquo; state according to the composition rules in variables in ESKF using IMUs reset the error state Source: Markley 2014 What if several measurements come in without IMU / propagation in between (i.</description></item><item><title>50.5 Error-State Kalman Filter</title><link>https://salehahr.github.io/studienarbeit/50.5-error-state-kalman-filter/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/50.5-error-state-kalman-filter/</guid><description>Source: Markley An EKF propagates the expectation and covariance of the state The MEKF propagates the expectation and the covariance of the error state Source: Whampsey MEKF Previously: orientation is represented by one state Now: orientation is split up into  a large signal q_nom (nominal orientation) and a small signal (perturbation angle alpha) &amp;ndash; parametrises an error quaternion  This reformulates the error in terms of the group operation and so maintains the rotation invariance (rotation preserves the origin, length, angle between two vectors, orientation, etc.</description></item><item><title>Pizarro 2016 Schwarps</title><link>https://salehahr.github.io/studienarbeit/pizarro-2016-schwarps/</link><pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/pizarro-2016-schwarps/</guid><description>Author: Daniel Pizarro et al.
Abstract
Warp between two images of a deforming surface: a transformation that depict the geometric deformation between the two &amp;lsquo;maps points between images of a deforming surface&amp;rsquo; Current approach to enforce a warp&amp;rsquo;s smoothness: penalise its second order partial derivatives However this favours locally affine warps Does not capture the local projective component of the image deformation Propose: novel penalty to smooth the warp while capturing the deformation&amp;rsquo;s local projective structure Proposed penalty is based on equivalents to the Schwarzian derivatives Schwarzian derivatives: projective differential invariants exactly preserved by homographies Methodology to derive a set of PDEs with only homographies as the solutions Validation: Schwarps outperform existing warps in modeling and extrapolation power: perform better in deformable reconstruction methods Introduction/Related work</description></item><item><title>Feature matching</title><link>https://salehahr.github.io/studienarbeit/feature-matching/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/feature-matching/</guid><description>Source: http://medium.com/data-breach/introduction-to-feature-detection-and-matching-65e27179885d Backlinks: Bag of words , sparse/feature-based-vslam For matching between images, i.e. to establish a relationship (&amp;lsquo;correspondence&amp;rsquo;) between two images of the same scene or object.
Basic algorithm
Find/detect a set of identifying (&amp;lsquo;distinctive&amp;rsquo;) keypoints from all images to be matched Define a search region around each keypoint Extract and normalise the region content Compute a local descriptor from the normalised region Match local descriptors between the images Performance of matching methods depend on</description></item><item><title>IMU preintegration on manifold</title><link>https://salehahr.github.io/studienarbeit/imu-preintegration-on-manifold/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/imu-preintegration-on-manifold/</guid><description>Parent: IMU index Source: Forster 2017 IMU Preintegration Backlinks: IMU model Preintegration on manifold
Summarising all measurements between the keyframes i and j into a single measurement This preintegrated IMU measurement constrains the motion between two consecutive keyframes Assume IMU is synchronised with the camera The above equations already provide the summarised IMU measurements, however, the integration has to be repeated whenever the linearisation point at t=t_i changes i.</description></item><item><title>Non-Rigid Guided Matching (b/w KFs) in DefSLAM</title><link>https://salehahr.github.io/studienarbeit/non-rigid-guided-matching-b-w-kfs-in-defslam/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/non-rigid-guided-matching-b-w-kfs-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Backlinks: NRSfM in DefSLAM Matching between keyframes (used in deformation mapping in DefSLAM)
Use an estimated warp as a reference
To increase number of matches in the covisible keyframes Process
Matches are given by deformation tracking Estimate an initial warp between k and k* (covisible keyframes) how? Using this initial warp, estimate where a point would be seen in k* Define a search region around thesse estimated positions.</description></item><item><title>Mapping step-by-step in DefSLAM</title><link>https://salehahr.github.io/studienarbeit/mapping-step-by-step-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/mapping-step-by-step-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Parent: DefSLAM framework Steps
Recover warps between k and k* (s. [Non-Rigid Guided Matching (b/w KFs) in DefSLAM](non-rigid guided-matching-(b_w-kfs)-in-defslam.md)) with k: anchor keyframes, i.e. KFs where one of the observed map points was initialised with k*: set of best covisible keyframes warps: transformation between the images Ik to Ik* In DefSLAM, Schwarps (a family of warps using 2D Schwarzian equation regularisers) is used Schwarps has something to do with the infinitesimal planarity assumption of NRSfM [ NRSfM ] Process k* to get estimate of an up-to-scale surface  Input of NRSfM: warps [ Surface alignment ] Up-to-scale surface (\hat{S}_k) is aligned with the whole map in order to obtained the scaled surface Sk w.</description></item><item><title>NRSfM in DefSLAM</title><link>https://salehahr.github.io/studienarbeit/nrsfm-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/nrsfm-in-defslam/</guid><description>Parent: Mapping step-by-step in DefSLAM Source: Lamarca 2019 DefSLAM Assumptions
Isometric deformation Infinitesimal planarity [DEF]: any surface can be approximated as a plane at infinitesimal level, all the while maintaining its curvature at a global level The method used here is a local method &amp;ndash;&amp;gt; implies that it handles missing data and occlusions inherently
surface deformation is modelled locally for each point, under the above assumptions Embedding, phi_k of the scene surface</description></item><item><title>Tracking optimisation in DefSLAM</title><link>https://salehahr.github.io/studienarbeit/tracking-optimisation-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/tracking-optimisation-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Backlinks: Template substitution in DefSLAM Optimisation function
Minimises reprojection error (in the image) deformation energy (of the template) boundary nodes of the local zone are fixed (i.e. not set as arguments to the optimisation function) this makes the absolute camera pose observable how? in order to constrain the gauge freedoms Initial guess: values from previous optimisation (i.e. previous frame: t-1) Reprojection error robust against outliers due to Huber robust kernel</description></item><item><title>Forster 2017 IMU Preintegration</title><link>https://salehahr.github.io/studienarbeit/forster-2017-imu-preintegration/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/forster-2017-imu-preintegration/</guid><description>Authors: Forster et al
Abstract:
First contribution: preintegration theory (building up on Lupton&amp;rsquo;s work) what&amp;rsquo;s different from Lupton&amp;rsquo;s: addresses manifold structure of the rotation group, analytic derivation of all Jacobians Lupton&amp;rsquo;s work uses Euler angles Using Euler angles and techniques of Euclidian spaces for state propagation/covariance estimation is not properly invariant under rigid transformations uncertainty propagation, a-posteriori bias correction same as Lupton: integration performed in local frame, eliminating need for reintegrating when linearisation point changes Second contribution: integration of the preintegrated IMU model into a visual-inertial pipeline The system presented uses incremental smoothing for fast computation of the optimal MAP estimate Uses structureless model (3D landmarks are not part of the variables to be estimated) for visual measurements &amp;ndash;&amp;gt; allows eliminating large numbers of variables Motivation:</description></item><item><title>Showing correlation using error ellipses</title><link>https://salehahr.github.io/studienarbeit/showing-correlation-using-error-ellipses/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/showing-correlation-using-error-ellipses/</guid><description>Parent: Error ellipse/Confidence ellipse Source: rlabbe Kalman/Bayesian filters in Python A slanted ellipse implies correlation
The &amp;lsquo;thinner&amp;rsquo; side isn&amp;rsquo;t necessarily more accurate, it just means that the spread of data is reduced along this dimension (when viewing sensor data, for example) Example First epoch Yellow: prior (very uncertain about position) Green: evidence (more accurate in one of the dimensions than the other; more certainty compared to prior) Blue: posterior via multiplication Posterior retains the shape of the evidence (which has more certainty than the prior)</description></item><item><title>Expected value</title><link>https://salehahr.github.io/studienarbeit/expected-value/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/expected-value/</guid><description>Source: rlabbe Kalman/Bayesian filters in Python Example: if we take a thousand sensor readings, the readings won&amp;rsquo;t always be the same (due to the inherent noise).
The expected value &amp;lsquo;averages&amp;rsquo; all of the readings into a single value. This can be a mean (probabilities of all values assumed equal) Or if incorporating individual and different probabilities, the expectation isn&amp;rsquo;t the mean of the range of values Proven: the average of a large number of measurements will be very close to the actual weight</description></item><item><title>Chen 2018 SLAM-based dense surface reconstruction in MIS with AR</title><link>https://salehahr.github.io/studienarbeit/chen-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/chen-2018-mis-slam/</guid><description>Authors Chen et al
Abstract
Intra-operative dense surface reconstruction framework to provide geometry information from only monocular videos The proposed framework works well with rapid camera movements, however is not suitable for large deformations Only tweaks ORBSLAM to adjust between point density and computational performance Contents/Chapters Problems in medical AR:
tissue surface illumination tissue deformation rapid movements of the medical tool e.g. endoscope (s. also kidnapped robot problem for relocalisation, tracking mus therefore be robust) field of view often very small &amp;ldquo;A typical human uses 14 visual cues to perceive depth, only 3/14 are binocular vision related.</description></item><item><title>Information Filter</title><link>https://salehahr.github.io/studienarbeit/information-filter/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/information-filter/</guid><description>Parent: General Kalman Filter Source: Scaradozzi 2018 SLAM application in surgery also same assumptions as the EKF main difference: how the Gaussian belief is represented est. cov. — replaced by information matrix (IM) est. state — replaced by information vector (IV) superior to KF in the following ways data is filtered by summing up the IMs and IVs often numerically more stable Dual character of KF and IF</description></item><item><title>(Scaradozzi 2018) SLAM application in surgery</title><link>https://salehahr.github.io/studienarbeit/scaradozzi-2018-slam-application-in-surgery/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/scaradozzi-2018-slam-application-in-surgery/</guid><description>Abstract:
SLAM&amp;rsquo;s potential in image-guided surgery assuming static environment Review of main techniques in general robotics SLAM Insight into visual SLAM SLAM in surgery Chapters What is SLAM? Filter-based vs optimisation-based SLAM General Kalman Filter General EKF Unscented Kalman Filter Information Filter &amp;hellip;.
Takeaway
EKF is popular in surgery SLAM techniques Deformable environment encumbers precise registration and data fusion</description></item><item><title>Back-end optimisation</title><link>https://salehahr.github.io/studienarbeit/back-end-optimisation/</link><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/back-end-optimisation/</guid><description>Parent: Visual SLAM Implementation Framework Source: cometlabs (Camera pose optimisation)
To compensate for drift of pose estimation Traditionally using EKF ( filter-based ) simple implementation therefore good for small scale estimations Alternative: bundle adjustment (graph optimisation) joint optimisation of the camera pose and the 3D structure parameters combines numerical methods and graph theory increasingly favoured over filtering, due to the latter&amp;rsquo;s inherent inconsistency more efficient when combined with sub-mapping</description></item></channel></rss>