<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>filters/bayesian-filter on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/filters/bayesian-filter/</link><description>Recent content in filters/bayesian-filter on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/filters/bayesian-filter/index.xml" rel="self" type="application/rss+xml"/><item><title>50.2.10 Discrete Bayesian filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10-discrete-bayesian-filter/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10-discrete-bayesian-filter/</guid><description>Source: rlabbe Kalman/Bayesian filters in Python The Kalman filter is a subset of Bayesian filters
Predict and update steps like in the g-h filter Here: error percentages are used to implicitly compute the g and h parameters Steps
[Initialise our belief in the state] The predict step always degrades our knowledge (belief/prior) However, in the update step , we add another measurement. This, will always improve our knowledge regardless of noise, enabling convergence Limitations of the discrete Bayes filter</description></item><item><title>50.2.10.1 Discrete Bayesian Filter Predict Step</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10.1-discrete-bayesian-filter-predict-step/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10.1-discrete-bayesian-filter-predict-step/</guid><description>Parent: Discrete Bayesian filter Source: rlabbe Kalman/Bayesian filters in Python The predict step uses the total probability theorem.
Computes total probability of multiple possible events Uses the system model (propagates the states from prev. time step [posterior] to the next one); prediction Accounts for the uncertainty (kernel) in the prediction: produces a prior Generalise the uncertainty using a kernel (distributes the uncertainty over a range around the prediction) Integrate the kernel into the calculations by using convolution * Convolving the &amp;ldquo;current probabilistic estimate&amp;rdquo; with the &amp;ldquo;probabilistic estimate of how much we think the position has changed&amp;rdquo; (from system model) The prior is a &amp;lsquo;degraded&amp;rsquo; version of the belief i.</description></item><item><title>50.2.10.2 Bayesian Filter Update Step</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10.2-bayesian-filter-update-step/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.10.2-bayesian-filter-update-step/</guid><description>Parent: Discrete Bayesian filter Source: rlabbe Kalman/Bayesian filters in Python The update step uses Bayes' Theorem Produces the posterior by using the likelihood and the prior Also incorporates sensor data (measurements), as the measurements go into the likelihood calculation Update algorithm
Get a measurement, and associated belief about its accuracy Compute likelihood from the measurement and the measurement accuracy assumption Update the posterior using the likelihood and the prior</description></item><item><title>Deriving Kalman filter from Discrete Bayes using Gaussians</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/deriving-kalman-filter-from-discrete-bayes-using-gaussians/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/deriving-kalman-filter-from-discrete-bayes-using-gaussians/</guid><description>Parent: 1D Kalman filters Source: rlabbe Kalman/Bayesian filters in Python Replacing discrete Bayes with Gaussian distributions where the operators in the circles are as of yet undetermined</description></item><item><title>Limitations of the discrete Bayes filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/limitations-of-the-discrete-bayes-filter/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/limitations-of-the-discrete-bayes-filter/</guid><description>Parent: Discrete Bayesian filter Source: rlabbe Kalman/Bayesian filters in Python Limitations of the discrete Bayes filter
Scaling Dog tracking example is one-dimensional, but in real life we often want to track more things (e.g. 2D coordinates, velocities) Multidimensional case: store probabilities in a grid 4 tracked variables: O(n^4) per time step High computational cost with high dimensionality Filter is discrete and therefore gives discrete output But a lot of applications require continuous output Discretising a solution space can lead to lots of data (depending on accuracy required) &amp;ndash;&amp;gt; calculations for lots of different probabilities!</description></item></channel></rss>