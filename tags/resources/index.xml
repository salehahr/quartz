<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>-resources on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/resources/</link><description>Recent content in -resources on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Wed, 18 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://salehahr.github.io/zettelkasten/tags/resources/index.xml" rel="self" type="application/rss+xml"/><item><title>Baumgarte stabilisation over the SO(3) rotation group for control</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</guid><description>Author: Sebastien Gros</description></item><item><title>Baumgarte stabilisation over the SO(3) rotation group for control</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</guid><description>Author: Sebastien Gros</description></item><item><title>Schneider 2013 How to not make the EKF fail</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/schneider-2013-how-to-not-make-the-ekf-fail/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/schneider-2013-how-to-not-make-the-ekf-fail/</guid><description>Authors: Schneider, Georgakis URL: http://www.researchgate.net/publication/263942618_How_To_NOT_Make_the_Extended_Kalman_Filter_Fail/citations DOI 10.1021/ie300415d Measurement noise R, V (landmark) Kalman filter initial estimates Process noise Q and W (odometry) Kalman filter performance metric</description></item><item><title>Schneider 2013 How to not make the EKF fail</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/schneider-2013-how-to-not-make-the-ekf-fail/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/schneider-2013-how-to-not-make-the-ekf-fail/</guid><description>Authors: Schneider, Georgakis URL: http://www.researchgate.net/publication/263942618_How_To_NOT_Make_the_Extended_Kalman_Filter_Fail/citations DOI 10.1021/ie300415d Measurement noise R, V (landmark) Kalman filter initial estimates Process noise Q and W (odometry) Kalman filter performance metric</description></item><item><title>(Markley 2014) Fundamentals of Spacecraft Attitude Determination and Control</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2014/</link><pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2014/</guid><description>Authors: FL Markley, John Crassidis DOI: 10.1007/978-1-4939-0802-8
Note/Nomenclature:
This book interpetes rotations/transformations in the passive/alias sense (I&amp;rsquo;m not a fan) Quaternions in JPL convention instead of Hamiltonian (not a fan of this either&amp;hellip;) Rotation matrix = attitude matrix Introduction
Attitude determination: memoryless approach without using statistics Attitude estimation: approaches with memory, uses statistical info from a series of measurements filter approaches uses a dynamic motion model of the object Quaternions Quaternion conventions Quaternion multiplication Rotations &amp;ldquo;Euler&amp;rsquo;s theorem: any rotation is a rotation about a fixed axis&amp;rdquo;</description></item><item><title>(Markley 2014) Fundamentals of Spacecraft Attitude Determination and Control</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2014/</link><pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2014/</guid><description>Authors: FL Markley, John Crassidis DOI: 10.1007/978-1-4939-0802-8
Note/Nomenclature:
This book interpetes rotations/transformations in the passive/alias sense (I&amp;rsquo;m not a fan) Quaternions in JPL convention instead of Hamiltonian (not a fan of this either&amp;hellip;) Rotation matrix = attitude matrix Introduction
Attitude determination: memoryless approach without using statistics Attitude estimation: approaches with memory, uses statistical info from a series of measurements filter approaches uses a dynamic motion model of the object Quaternions Quaternion conventions Quaternion multiplication Rotations &amp;ldquo;Euler&amp;rsquo;s theorem: any rotation is a rotation about a fixed axis&amp;rdquo;</description></item><item><title>Maley 2013 MEKF for Nonspinning Guided Projectiles</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</guid><description>Source: http://apps.dtic.mil/sti/citations/ADA588831</description></item><item><title>Maley 2013 MEKF for Nonspinning Guided Projectiles</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</guid><description>Source: http://apps.dtic.mil/sti/citations/ADA588831</description></item><item><title>Markley 2003 Attitude Error Representations for Kalman Filtering</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</guid><description>Source: http://scholar.google.com/scholar?cluster=9266330323139560128&amp;amp;hl=en&amp;amp;as_sdt=0,5 Author: FL Markley
Motivation
Quaternion as an attitude representation
Good: lowest dimensionality while being a globally nonsingular representation Not so good: must obey a unit norm constraint In research, various methods for either getting around the norm constraint, or to enforce it
Most successful method employs the global attitude as a unit quaternion with a 3-comp attitude error representation
MEKF doesn&amp;rsquo;t estimate the quaternion state.</description></item><item><title>Markley 2003 Attitude Error Representations for Kalman Filtering</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</guid><description>Source: http://scholar.google.com/scholar?cluster=9266330323139560128&amp;amp;hl=en&amp;amp;as_sdt=0,5 Author: FL Markley
Motivation
Quaternion as an attitude representation
Good: lowest dimensionality while being a globally nonsingular representation Not so good: must obey a unit norm constraint In research, various methods for either getting around the norm constraint, or to enforce it
Most successful method employs the global attitude as a unit quaternion with a 3-comp attitude error representation
MEKF doesn&amp;rsquo;t estimate the quaternion state.</description></item><item><title>Whampsey MEKF</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/whampsey-mekf/</link><pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/whampsey-mekf/</guid><description>http://matthewhampsey.github.io/blog/2020/07/18/mekf
Motivation:
Working with noisy IMU measurements IMUs usually provide redundant information that can be used to improve dead-reckoning Uses: Hamilton quaternion convention Which orientation parametrisation to choose? Error-State Kalman Filter</description></item><item><title>Whampsey MEKF</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/whampsey-mekf/</link><pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/whampsey-mekf/</guid><description>http://matthewhampsey.github.io/blog/2020/07/18/mekf
Motivation:
Working with noisy IMU measurements IMUs usually provide redundant information that can be used to improve dead-reckoning Uses: Hamilton quaternion convention Which orientation parametrisation to choose? Error-State Kalman Filter</description></item><item><title>ESKF repos</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/eskf-repos/</link><pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/eskf-repos/</guid><description>C++ http://github.com/skrogh/msf_ekf http://github.com/je310/ESKF http://github.com/hobbeshunter/IMU_EKF (only IMU)
Python http://github.com/enginBozkurt/Error-State-Extended-Kalman-Filter http://github.com/uoip/stereo_vio_eskf (unsuccessful) &amp;ndash; uses average IMU readings http://github.com/aipiano/ESEKF_IMU</description></item><item><title>Diagnosis bladder cancer</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/diagnosis-bladder-cancer/</link><pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/diagnosis-bladder-cancer/</guid><description>http://www.cancer.org/cancer/bladder-cancer/detection-diagnosis-staging/how-diagnosed.html</description></item><item><title>Jeon 2009 Kinematic Kalman Filter for Robot End-Effector Sensing</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</guid><description>Backlinks: Discussion 2021-05-25 Authors: Jeon and Tomizuka
Abstract
inaccuracies in estimation of EE motion can come from kinematic error (error in parameters in kinematic equations)
to overcome this: take direct measurements e.g. using vision, but vision has high latency IMUs are used to provide interframe data fuse camera and IMU in a kinematic Kalman filter (KKF) framework. Note: uses ESKF
effect of camera measurement delay, augmenting the KF states to also estimate the time delay</description></item><item><title>Jeon 2009 Kinematic Kalman Filter for Robot End-Effector Sensing</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</guid><description>Backlinks: Discussion 2021-05-25 Authors: Jeon and Tomizuka
Abstract
inaccuracies in estimation of EE motion can come from kinematic error (error in parameters in kinematic equations)
to overcome this: take direct measurements e.g. using vision, but vision has high latency IMUs are used to provide interframe data fuse camera and IMU in a kinematic Kalman filter (KKF) framework. Note: uses ESKF
effect of camera measurement delay, augmenting the KF states to also estimate the time delay</description></item><item><title>(Hibbeler) Dynamics</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/hibbeler-dynamics/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/hibbeler-dynamics/</guid><description>Author: Russell Hibbeler Contents
Kinematics, kinetics of particle [planar] rigid body [3D] rigid body Vibrations Kinematics primer</description></item><item><title>(Hibbeler) Dynamics</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/hibbeler-dynamics/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/hibbeler-dynamics/</guid><description>Author: Russell Hibbeler Contents
Kinematics, kinetics of particle [planar] rigid body [3D] rigid body Vibrations Kinematics primer</description></item><item><title>(Woernle) Mehrkoerpersysteme</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/woernle-mehrkoerpersysteme/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/woernle-mehrkoerpersysteme/</guid><description>Author: Christoph Woernle Contents:
Kinematics, kinetics (Dynamik) Some basics Converting velocity from CS1 to CS0 Chaining rotation matrices and angular velocities [Poisson equation for skew symmetric matrix of angular velocity](poisson equation for skew-symmetric-matrix-of-angular-velocity.md) Differentiation in different coordinate systems Kinematics primer Reversed kinematics relations Rotations as xyz Bryan-Tait angles (Kardanwinkel) Holonomic systems, non-holonomic systems Holonomic constraints</description></item><item><title>(Woernle) Mehrkoerpersysteme</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/woernle-mehrkoerpersysteme/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/woernle-mehrkoerpersysteme/</guid><description>Author: Christoph Woernle Contents:
Kinematics, kinetics (Dynamik) Some basics Converting velocity from CS1 to CS0 Chaining rotation matrices and angular velocities [Poisson equation for skew symmetric matrix of angular velocity](poisson equation for skew-symmetric-matrix-of-angular-velocity.md) Differentiation in different coordinate systems Kinematics primer Reversed kinematics relations Rotations as xyz Bryan-Tait angles (Kardanwinkel) Holonomic systems, non-holonomic systems Holonomic constraints</description></item><item><title>(Leiner) Digital Endoscope Design</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/leiner/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/leiner/</guid><description>Backlinks: Endoscopes URL: http://www.spiedigitallibrary.org/ebooks/SL/Digital-Endoscope-Design/1/Digital-Endoscope-Design/10.1117/3.2235283.ch1?SSO=1
Notes Insertion of an endoscope Types of endoscopes Endoscope system components Endoscope specification</description></item><item><title>(Leiner) Digital Endoscope Design</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/leiner/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/leiner/</guid><description>Backlinks: Endoscopes URL: http://www.spiedigitallibrary.org/ebooks/SL/Digital-Endoscope-Design/1/Digital-Endoscope-Design/10.1117/3.2235283.ch1?SSO=1
Notes Insertion of an endoscope Types of endoscopes Endoscope system components Endoscope specification</description></item><item><title>Endoscope/cystoscopy pics/videos</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/endoscope-cystoscopy-pics-videos/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/endoscope-cystoscopy-pics-videos/</guid><description>Backlinks: Discussion 2021-05-21 Rigid endoscope for cystoscopy
Source: http://www.ebay.com/itm/113780645426 Source: http://www.researchgate.net/figure/Intraoperative-image-of-the-rigid-cystoscope-entering-the-bladder-through-the-screw-tip_fig2_322897289 Source: http://www.youtube.com/watch?v=1gEpz9wijoY http://www.maestro-portal.eu/procedure/detail/4 Videos: Semi-Rigid Ureteroscopy and Laser Lithotripsy for Ureter Stones
Source: http://www.medicinenet.com/how_painful_is_a_cystoscopy/article.htm</description></item><item><title>(Science Focus) How can one eye alone provide depth perception</title><link>https://salehahr.github.io/zettelkasten/bibliography/science-focus/</link><pubDate>Mon, 17 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/science-focus/</guid><description>Source: http://www.sciencefocus.com/the-human-body/how-can-one-eye-alone-provide-depth-perception/
Author: Hilary Guite
In humans with normal binocular vision, depth perception is obtained using the parallax in the two overlapping fields of vision (&amp;ldquo;binocular disparity&amp;rdquo;)
Each single field of vision has a slightly different view to the other If vision in one eye is impaired, depth perception is still obtainable even with only one eye. Some tricks that the brain uses:
We know the real size of things Using perspective, e.</description></item><item><title>(Science Focus) How can one eye alone provide depth perception</title><link>https://salehahr.github.io/zettelkasten/bibliography/science-focus/</link><pubDate>Mon, 17 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/science-focus/</guid><description>Source: http://www.sciencefocus.com/the-human-body/how-can-one-eye-alone-provide-depth-perception/
Author: Hilary Guite
In humans with normal binocular vision, depth perception is obtained using the parallax in the two overlapping fields of vision (&amp;ldquo;binocular disparity&amp;rdquo;)
Each single field of vision has a slightly different view to the other If vision in one eye is impaired, depth perception is still obtainable even with only one eye. Some tricks that the brain uses:
We know the real size of things Using perspective, e.</description></item><item><title>Solà 2017 Quaternion kinematics for ESKF</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2017-quaternion-kinematics-for-eskf/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2017-quaternion-kinematics-for-eskf/</guid><description>Link: http://www.iri.upc.edu/people/jsola/JoanSola/objectes/notes/kinematics.pdf
Author: Joan Solà Abstract:
Primer on quaternion/rotation group math Math for error state Kalman filters using IMUs Contents/Chapters:
Quaternions Rotations, s. also SO(3) 3D rotation group Quaternion conventions Perturbations, derivatives, integrals Error-State Kalman Filter for IMU-driven systems Variables in ESKF IMU measurement model IMU motion model [The initial gravity vector/orientation for the IMU ESKF](the initial gravity-vector_orientation-for-the-imu-eskf.</description></item><item><title>Solà 2017 Quaternion kinematics for ESKF</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2017-quaternion-kinematics-for-eskf/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2017-quaternion-kinematics-for-eskf/</guid><description>Link: http://www.iri.upc.edu/people/jsola/JoanSola/objectes/notes/kinematics.pdf
Author: Joan Solà Abstract:
Primer on quaternion/rotation group math Math for error state Kalman filters using IMUs Contents/Chapters:
Quaternions Rotations, s. also SO(3) 3D rotation group Quaternion conventions Perturbations, derivatives, integrals Error-State Kalman Filter for IMU-driven systems Variables in ESKF IMU measurement model IMU motion model [The initial gravity vector/orientation for the IMU ESKF](the initial gravity-vector_orientation-for-the-imu-eskf.</description></item><item><title>Cyril Stachniss EKF-SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cyril-stachniss-ekf-slam/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cyril-stachniss-ekf-slam/</guid><description>Links:
Course material: http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/ Lectures: http://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_&amp;amp;feature=g-list</description></item><item><title>Solà 2014 SLAM with EKF</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2014-slam-with-ekf/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sol%C3%A0-2014-slam-with-ekf/</guid><description> Notes on EKF-SLAM that uses landmarks MATLAB code Notes on partial landmark initialisation (convariance matrix) Notes on the linearity of the observation function in scale</description></item><item><title>Discussion 2021-05-10</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/discussion-2021-05-10/</link><pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/discussion-2021-05-10/</guid><description>Agenda
Change/Reduction of scope of SA (from fusing IMU with camera) to using sensor fusion to determine transformation parameters between IMU and camera Camera and IMU setup involves kinematic modelling (not fixed transformation as previously assumed!) Offline implementation in Python/MATLAB (scripting language) HiWi tasks can include DefSLAM bindings / interface C++ bindings of skrogh EKF implementation? HiWi prioritises Versuchsstand for now Tasks
Find an EKF implementation that works well and can be used with DefSLAM + IMU data implement kinematic model equations in the prediction-step, s.</description></item><item><title>(Weiss Thesis) Vision based navigation for micro helicopters</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</guid><description>Source Backlinks
Authors Stephan Weiss Abstract
Issues that arise during state estimation and sensor self-calibration Application area: large and unknown areas, micro helicopter Vision based method used uses SfM, is compares mapless and map-based methods Statistical and modular sensor fusion strategy recovery of pose and drifts modular: camera as a black box sensor, allows other sensors additionally Observability analysis Literature review
Fusing IMU with monocular vision: given extrinsic parameters , an IMU is able to recover metric scale, as well as help transition across short vision failure period Armesto et al.</description></item><item><title>(Weiss Thesis) Vision based navigation for micro helicopters</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</guid><description>Source Backlinks
Authors Stephan Weiss Abstract
Issues that arise during state estimation and sensor self-calibration Application area: large and unknown areas, micro helicopter Vision based method used uses SfM, is compares mapless and map-based methods Statistical and modular sensor fusion strategy recovery of pose and drifts modular: camera as a black box sensor, allows other sensors additionally Observability analysis Literature review
Fusing IMU with monocular vision: given extrinsic parameters , an IMU is able to recover metric scale, as well as help transition across short vision failure period Armesto et al.</description></item><item><title>resource IMU common specifications, error models etc</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/resource-imu-common-specifications-error-models-etc/</link><pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/resource-imu-common-specifications-error-models-etc/</guid><description>Parent: IMU Source: http://www.vectornav.com/resources/imu-specifications
IMU common specifications, bias, scale factor, orthogonality errors, and acceleration sensitivity for gyroscopes.
Source: Woodman - An introduction to inertial navigation Source: Quinchia - A Comparison between Different Error Modeling of MEMS Applied to GPS/INS Integrated Systems
3.2. State-Space Representation for Different Bias Models
First order Gauss-Markov (GM) Random walk Autoregressive process</description></item><item><title>MKok 2017 Using inertial sensors for position and orientation estimation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</guid><description>Source: http://arxiv.org/abs/1704.06053 Authors: M Kok, JD Hol, TB Schön
Abstract
Contents/Chapters Quaternions Probabilistic models for IMU Orientation parametrisations Which orientation parametrisation to choose? Linearisation of an orientation in SO(3) IMU measurement model Modelling noise and bias for IMU IMU motion models IMU prior models</description></item><item><title>MKok 2017 Using inertial sensors for position and orientation estimation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</guid><description>Source: http://arxiv.org/abs/1704.06053 Authors: M Kok, JD Hol, TB Schön
Abstract
Contents/Chapters Quaternions Probabilistic models for IMU Orientation parametrisations Which orientation parametrisation to choose? Linearisation of an orientation in SO(3) IMU measurement model Modelling noise and bias for IMU IMU motion models IMU prior models</description></item><item><title>ORBSLAM2 unofficial documentation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam2-unofficial-documentation/</link><pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam2-unofficial-documentation/</guid><description>Partially done, abandonned: http://github.com/raulmur/ORB_SLAM2/compare/master&amp;hellip;AlejandroSilvestri:master In Spanish: http://alejandrosilvestri.github.io/os1/doc/html/</description></item><item><title>Pizarro 2016 Schwarps</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</link><pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</guid><description>Author: Daniel Pizarro et al.
Abstract
Warp between two images of a deforming surface: a transformation that depict the geometric deformation between the two &amp;lsquo;maps points between images of a deforming surface&amp;rsquo; Current approach to enforce a warp&amp;rsquo;s smoothness: penalise its second order partial derivatives However this favours locally affine warps Does not capture the local projective component of the image deformation Propose: novel penalty to smooth the warp while capturing the deformation&amp;rsquo;s local projective structure Proposed penalty is based on equivalents to the Schwarzian derivatives Schwarzian derivatives: projective differential invariants exactly preserved by homographies Methodology to derive a set of PDEs with only homographies as the solutions Validation: Schwarps outperform existing warps in modeling and extrapolation power: perform better in deformable reconstruction methods Introduction/Related work</description></item><item><title>Pizarro 2016 Schwarps</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</link><pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</guid><description>Author: Daniel Pizarro et al.
Abstract
Warp between two images of a deforming surface: a transformation that depict the geometric deformation between the two &amp;lsquo;maps points between images of a deforming surface&amp;rsquo; Current approach to enforce a warp&amp;rsquo;s smoothness: penalise its second order partial derivatives However this favours locally affine warps Does not capture the local projective component of the image deformation Propose: novel penalty to smooth the warp while capturing the deformation&amp;rsquo;s local projective structure Proposed penalty is based on equivalents to the Schwarzian derivatives Schwarzian derivatives: projective differential invariants exactly preserved by homographies Methodology to derive a set of PDEs with only homographies as the solutions Validation: Schwarps outperform existing warps in modeling and extrapolation power: perform better in deformable reconstruction methods Introduction/Related work</description></item><item><title>DBoW2 weighing and scoring</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</guid><description>Source: http://github.com/dorian3d/DBow</description></item><item><title>DBoW2 weighing and scoring</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</guid><description>Source: http://github.com/dorian3d/DBow</description></item><item><title>Intro to bladder cancer</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/intro-to-bladder-cancer/</link><pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/intro-to-bladder-cancer/</guid><description>http://www.cancer.net/cancer-types/bladder-cancer/introduction</description></item><item><title>The making of EndoSLAM dataset</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/the-making-of-endoslam-dataset/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/the-making-of-endoslam-dataset/</guid><description>http://www.youtube.com/watch?v=G_LCe0aWWdQ Github: http://github.com/CapsuleEndoscope/EndoSLAM</description></item><item><title>Forster 2017 IMU Preintegration</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/forster-2017-imu-preintegration/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/forster-2017-imu-preintegration/</guid><description>Authors: Forster et al
Abstract:
First contribution: preintegration theory (building up on Lupton&amp;rsquo;s work) what&amp;rsquo;s different from Lupton&amp;rsquo;s: addresses manifold structure of the rotation group, analytic derivation of all Jacobians Lupton&amp;rsquo;s work uses Euler angles Using Euler angles and techniques of Euclidian spaces for state propagation/covariance estimation is not properly invariant under rigid transformations uncertainty propagation, a-posteriori bias correction same as Lupton: integration performed in local frame, eliminating need for reintegrating when linearisation point changes Second contribution: integration of the preintegrated IMU model into a visual-inertial pipeline The system presented uses incremental smoothing for fast computation of the optimal MAP estimate Uses structureless model (3D landmarks are not part of the variables to be estimated) for visual measurements &amp;ndash;&amp;gt; allows eliminating large numbers of variables Motivation:</description></item><item><title>Forster 2017 IMU Preintegration</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/forster-2017-imu-preintegration/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/forster-2017-imu-preintegration/</guid><description>Authors: Forster et al
Abstract:
First contribution: preintegration theory (building up on Lupton&amp;rsquo;s work) what&amp;rsquo;s different from Lupton&amp;rsquo;s: addresses manifold structure of the rotation group, analytic derivation of all Jacobians Lupton&amp;rsquo;s work uses Euler angles Using Euler angles and techniques of Euclidian spaces for state propagation/covariance estimation is not properly invariant under rigid transformations uncertainty propagation, a-posteriori bias correction same as Lupton: integration performed in local frame, eliminating need for reintegrating when linearisation point changes Second contribution: integration of the preintegrated IMU model into a visual-inertial pipeline The system presented uses incremental smoothing for fast computation of the optimal MAP estimate Uses structureless model (3D landmarks are not part of the variables to be estimated) for visual measurements &amp;ndash;&amp;gt; allows eliminating large numbers of variables Motivation:</description></item><item><title>Visual-inertial datasets</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/visual-inertial-datasets/</link><pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/visual-inertial-datasets/</guid><description>http://sites.google.com/view/awesome-slam-datasets/home
http://fpv.ifi.uzh.ch/ Aggressive drone racing http://www.lirmm.fr/aqualoc/ Underwater Monochromatic http://vision.in.tum.de/data/datasets/visual-inertial-dataset TUM indoor/urban, slides fisheye cameraUsed in ORBSLAM3 http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets EUROC MAV stereo, monochrUsed in ORBSLAM3</description></item><item><title>Grisetti 2011 - Tutorial graph-based SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</guid><description>temp
Backlinks: What is SLAM? Abstract
formulate SLAM using a graph nodes: poses of the robot (as well as landmark postiions) at different points in time edges: constraints between poses come from sensor measurements/observations robot movement/control input constraints can contradict each other, due to effect of noise in sensor readings solve the graph, i.e. compute the map: find the spatial configuration of the nodes that best satisfy the constraints/edges tutorial for back-end (optimisation) part of graph-based SLAM :: Navigation task: requires a map and knowledge of current position relative to locations in the map</description></item><item><title>Grisetti 2011 - Tutorial graph-based SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</guid><description>temp
Backlinks: What is SLAM? Abstract
formulate SLAM using a graph nodes: poses of the robot (as well as landmark postiions) at different points in time edges: constraints between poses come from sensor measurements/observations robot movement/control input constraints can contradict each other, due to effect of noise in sensor readings solve the graph, i.e. compute the map: find the spatial configuration of the nodes that best satisfy the constraints/edges tutorial for back-end (optimisation) part of graph-based SLAM :: Navigation task: requires a map and knowledge of current position relative to locations in the map</description></item><item><title>(Mur-Artal 2017) VI-ORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</guid><description>Backlinks: [keyframe-based tightly-coupled multisensor slam](keyframe-based tightly-coupled multisensor slam.md), todo , works of-possible-interest URL: http://ieeexplore.ieee.org/abstract/document/7817784, Authors: Mur-Artal, Tardós Code: http://paperswithcode.com/paper/visual-inertial-monocular-slam-with-map-reuse Results (video): http://www.youtube.com/watch?v=JXRCSovuxbA
Abstract
current VI odometry approaches: drift accumulates due to lack of loop closure therefore there is a need for tightly-coupled VI-SLAM with loop closure and map reuse here: focus on monocular case, but applicable to other camera configurations builds on ORB-SLAM (from same author) IMU initialisation method (initialises: scale, gravity direction, velocities, gyroscope bias, accelerometer bias) depends on visual monocular initialisation (coupled initialisation) Other works: recent tightly-coupled VIO (both filtering- and optimisation-based) lack loop closure, so drift accumulates</description></item><item><title>(Mur-Artal 2017) VI-ORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</guid><description>Backlinks: [keyframe-based tightly-coupled multisensor slam](keyframe-based tightly-coupled multisensor slam.md), todo , works of-possible-interest URL: http://ieeexplore.ieee.org/abstract/document/7817784, Authors: Mur-Artal, Tardós Code: http://paperswithcode.com/paper/visual-inertial-monocular-slam-with-map-reuse Results (video): http://www.youtube.com/watch?v=JXRCSovuxbA
Abstract
current VI odometry approaches: drift accumulates due to lack of loop closure therefore there is a need for tightly-coupled VI-SLAM with loop closure and map reuse here: focus on monocular case, but applicable to other camera configurations builds on ORB-SLAM (from same author) IMU initialisation method (initialises: scale, gravity direction, velocities, gyroscope bias, accelerometer bias) depends on visual monocular initialisation (coupled initialisation) Other works: recent tightly-coupled VIO (both filtering- and optimisation-based) lack loop closure, so drift accumulates</description></item><item><title>Badias 2020 MORPH-DSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</guid><description>URL: http://arxiv.org/pdf/2009.00576.pdf Video: http://www.youtube.com/watch?v=P_QN8Nv&amp;ndash;_g To read!</description></item><item><title>Badias 2020 MORPH-DSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</guid><description>URL: http://arxiv.org/pdf/2009.00576.pdf Video: http://www.youtube.com/watch?v=P_QN8Nv&amp;ndash;_g To read!</description></item><item><title>(AtsushiSakai) PythonRobotics</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/atsushisakai-pythonrobotics/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/atsushisakai-pythonrobotics/</guid><description>http://nbviewer.jupyter.org/github/AtsushiSakai/PythonRobotics/</description></item><item><title>(rlabbe) Kalman/Bayesian filters in Python</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</guid><description>URL: http://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python nbviewer link: http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb Abstract:
Introductory text with Python code Caveat: most of the code is written for didactic purposes, may not be the most efficient solution (nor numerically stable) Recommended other works s. Works of possible interest Chapters
Preface Why Kalman filters? [Aim and main principle of Kalman filters](aim and-main-principle-of-kalman-filters.md) Expected value g-h filter or α-β filter Discrete Bayesian filter Gaussian distribution 1D Kalman filters Multivariate Kalman filters</description></item><item><title>(rlabbe) Kalman/Bayesian filters in Python</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</guid><description>URL: http://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python nbviewer link: http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb Abstract:
Introductory text with Python code Caveat: most of the code is written for didactic purposes, may not be the most efficient solution (nor numerically stable) Recommended other works s. Works of possible interest Chapters
Preface Why Kalman filters? [Aim and main principle of Kalman filters](aim and-main-principle-of-kalman-filters.md) Expected value g-h filter or α-β filter Discrete Bayesian filter Gaussian distribution 1D Kalman filters Multivariate Kalman filters</description></item><item><title>(rlabbe) Kalman/Bayesian filters in Python</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/rlabbe-kalman-bayesian-filters-in-python/</guid><description>URL: http://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python nbviewer link: http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb Abstract:
Introductory text with Python code Caveat: most of the code is written for didactic purposes, may not be the most efficient solution (nor numerically stable) Recommended other works s. Works of possible interest Chapters
Preface Why Kalman filters? [Aim and main principle of Kalman filters](aim and-main-principle-of-kalman-filters.md) Expected value g-h filter or α-β filter Discrete Bayesian filter Gaussian distribution 1D Kalman filters Multivariate Kalman filters</description></item><item><title>Cadena 2016 Past, Present, and Future of SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</guid><description>Authors Cadena et al
Abstract
cited by 1.2k people &amp;ldquo;This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM&amp;rdquo; Recommended other works s. Works of possible interest Contents/Chapters Takeaway</description></item><item><title>Cadena 2016 Past, Present, and Future of SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</guid><description>Authors Cadena et al
Abstract
cited by 1.2k people &amp;ldquo;This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM&amp;rdquo; Recommended other works s. Works of possible interest Contents/Chapters Takeaway</description></item><item><title>Durrant-Whyte 2006 SLAM Tutorial Part I</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</guid><description>Backlinks: Works of possible interest Authors: Bailey, Durrant-Whyte
Abstract:
Contents/Chapters
Takeaway</description></item><item><title>Durrant-Whyte 2006 SLAM Tutorial Part I</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</guid><description>Backlinks: Works of possible interest Authors: Bailey, Durrant-Whyte
Abstract:
Contents/Chapters
Takeaway</description></item><item><title>Chen 2018 Review of VI SLAM</title><link>https://salehahr.github.io/zettelkasten/bibliography/chen-2018-review/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/chen-2018-review/</guid><description>Source: http://www.mdpi.com/2218-6581/7/3/45
Authors: Chen et. al
Abstract Survey on visual-inertial SLAM over the last 10 years Aspects: filtering vs optimisation based, camera type, sensor fusion type Explains core theory of SLAM, feature extraction, feature tracking, loop closure Experimental comparison of filtering-based and optimisation-based methods Research trends for VI-SLAM Recommended other works s. Works of possible interest Contents/Chapters SLAM SLAM: build a real-time map of the unknown environment based on sensor data, while the sensor (robot) itself is traversing the environment</description></item><item><title>Chen 2018 Review of VI SLAM</title><link>https://salehahr.github.io/zettelkasten/bibliography/chen-2018-review/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/chen-2018-review/</guid><description>Source: http://www.mdpi.com/2218-6581/7/3/45
Authors: Chen et. al
Abstract Survey on visual-inertial SLAM over the last 10 years Aspects: filtering vs optimisation based, camera type, sensor fusion type Explains core theory of SLAM, feature extraction, feature tracking, loop closure Experimental comparison of filtering-based and optimisation-based methods Research trends for VI-SLAM Recommended other works s. Works of possible interest Contents/Chapters SLAM SLAM: build a real-time map of the unknown environment based on sensor data, while the sensor (robot) itself is traversing the environment</description></item><item><title>Chen 2018 SLAM-based dense surface reconstruction in MIS with AR</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</guid><description>Authors Chen et al
Abstract
Intra-operative dense surface reconstruction framework to provide geometry information from only monocular videos The proposed framework works well with rapid camera movements, however is not suitable for large deformations Only tweaks ORBSLAM to adjust between point density and computational performance Contents/Chapters Problems in medical AR:
tissue surface illumination tissue deformation rapid movements of the medical tool e.g. endoscope (s. also kidnapped robot problem for relocalisation, tracking mus therefore be robust) field of view often very small &amp;ldquo;A typical human uses 14 visual cues to perceive depth, only 3/14 are binocular vision related.</description></item><item><title>Chen 2018 SLAM-based dense surface reconstruction in MIS with AR</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</guid><description>Authors Chen et al
Abstract
Intra-operative dense surface reconstruction framework to provide geometry information from only monocular videos The proposed framework works well with rapid camera movements, however is not suitable for large deformations Only tweaks ORBSLAM to adjust between point density and computational performance Contents/Chapters Problems in medical AR:
tissue surface illumination tissue deformation rapid movements of the medical tool e.g. endoscope (s. also kidnapped robot problem for relocalisation, tracking mus therefore be robust) field of view often very small &amp;ldquo;A typical human uses 14 visual cues to perceive depth, only 3/14 are binocular vision related.</description></item><item><title>Song 2018 MIS-SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</guid><description>Authors Song et al Backlinks: referred to in Lamarca 2019 as a stereovisual deformable SLAM, uses CPU and GPU, nonlinear optimisation Video: http://www.youtube.com/watch?v=2pXokldQBWM
Abstract
Uses CPU and GPU CPU for ORBSLAM (initial global position) GPU for deformable tracking and dense mapping Contents/Chapters
Poor localisation of scope in MIS, compared with open surgery Related works mentioned don&amp;rsquo;t provide a RT and robust solution for localisation while reconstructing dense deformable surfaces focus on the monocular scope, fail to solve the problem of missing scale Fast movement makes visual odometry unstable causes blurry images worsens registrations ORB-SLAM proven to be suitable for coupling with dense deformable SLAM Initial tracking: ORB-SLAM</description></item><item><title>Song 2018 MIS-SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</guid><description>Authors Song et al Backlinks: referred to in Lamarca 2019 as a stereovisual deformable SLAM, uses CPU and GPU, nonlinear optimisation Video: http://www.youtube.com/watch?v=2pXokldQBWM
Abstract
Uses CPU and GPU CPU for ORBSLAM (initial global position) GPU for deformable tracking and dense mapping Contents/Chapters
Poor localisation of scope in MIS, compared with open surgery Related works mentioned don&amp;rsquo;t provide a RT and robust solution for localisation while reconstructing dense deformable surfaces focus on the monocular scope, fail to solve the problem of missing scale Fast movement makes visual odometry unstable causes blurry images worsens registrations ORB-SLAM proven to be suitable for coupling with dense deformable SLAM Initial tracking: ORB-SLAM</description></item><item><title>Wikipedia Lokalisierung</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-lokalisierung/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-lokalisierung/</guid><description>Source: http://de.wikipedia.org/wiki/Lokalisierung_(Robotik Localisation Particle filters Categories of sensors for localisation</description></item><item><title>Wikipedia Lokalisierung</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-lokalisierung/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-lokalisierung/</guid><description>Source: http://de.wikipedia.org/wiki/Lokalisierung_(Robotik Localisation Particle filters Categories of sensors for localisation</description></item><item><title>Qin 2019 General Optimization-based Framework (Multisensor)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</guid><description>Authors: Qin et al Code: http://github.com/HKUST-Aerial-Robotics/VINS-Fusion (uses ROS)
Abstract:
odometry estimation with multiple sensors, general framework which is optimisation-based demonstrated combinations: stereo cameras monocular cam + IMU stereo cams + IMU sensor = factor in the framework comparison with other state-of-the-art algos Aim:
to create a general algo which supports different multisensor suites also for redundancy: in case of sensor failure, it can be switched out easily Related work:</description></item><item><title>Qin 2019 General Optimization-based Framework (Multisensor)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</guid><description>Authors: Qin et al Code: http://github.com/HKUST-Aerial-Robotics/VINS-Fusion (uses ROS)
Abstract:
odometry estimation with multiple sensors, general framework which is optimisation-based demonstrated combinations: stereo cameras monocular cam + IMU stereo cams + IMU sensor = factor in the framework comparison with other state-of-the-art algos Aim:
to create a general algo which supports different multisensor suites also for redundancy: in case of sensor failure, it can be switched out easily Related work:</description></item><item><title>Works of possible interest</title><link>https://salehahr.github.io/zettelkasten/bibliography/works-of-possible-interest/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/works-of-possible-interest/</guid><description>General SLAM Cadena 2016 &amp;ndash; Past, Present, and Future of SLAM durrant-whyte 2006 slam tutorial part i Prerequisites g2o paper - graph-based SLAM Existing SLAM algorithms MonoSLAM, works by Andrew Davison focusing on fusion instead of vision-only SLAM
Maplab (filtering-based) not looking at filtering-based algos
mentioned in the Chen 2018 Review of VI SLAM paper:
ORB-SLAM paper — ORB features VIORB implementation ORB-SLAM3 (improves on ORBSLAM, incl.</description></item><item><title>Works of possible interest</title><link>https://salehahr.github.io/zettelkasten/bibliography/works-of-possible-interest/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/bibliography/works-of-possible-interest/</guid><description>General SLAM Cadena 2016 &amp;ndash; Past, Present, and Future of SLAM durrant-whyte 2006 slam tutorial part i Prerequisites g2o paper - graph-based SLAM Existing SLAM algorithms MonoSLAM, works by Andrew Davison focusing on fusion instead of vision-only SLAM
Maplab (filtering-based) not looking at filtering-based algos
mentioned in the Chen 2018 Review of VI SLAM paper:
ORB-SLAM paper — ORB features VIORB implementation ORB-SLAM3 (improves on ORBSLAM, incl.</description></item><item><title>(Scaradozzi 2018) SLAM application in surgery</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/scaradozzi-2018/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/scaradozzi-2018/</guid><description>Abstract:
SLAM&amp;rsquo;s potential in image-guided surgery assuming static environment Review of main techniques in general robotics SLAM Insight into visual SLAM SLAM in surgery Chapters What is SLAM? Filter-based vs optimisation-based SLAM General Kalman Filter General EKF Unscented Kalman Filter Information Filter &amp;hellip;.
Takeaway
EKF is popular in surgery SLAM techniques Deformable environment encumbers precise registration and data fusion</description></item><item><title>(Scaradozzi 2018) SLAM application in surgery</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/scaradozzi-2018/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/scaradozzi-2018/</guid><description>Abstract:
SLAM&amp;rsquo;s potential in image-guided surgery assuming static environment Review of main techniques in general robotics SLAM Insight into visual SLAM SLAM in surgery Chapters What is SLAM? Filter-based vs optimisation-based SLAM General Kalman Filter General EKF Unscented Kalman Filter Information Filter &amp;hellip;.
Takeaway
EKF is popular in surgery SLAM techniques Deformable environment encumbers precise registration and data fusion</description></item><item><title>Lamarca 2020 DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</guid><description>URL: http://arxiv.org/abs/1908.08918 Authors: Lamarca et al Code: http://github.com/UZ-SLAMLab/DefSLAM Results (video): http://www.youtube.com/watch?v=6mmhD2_t6Gs Summary
First monocular SLAM for deformable environments in real-time Most other SLAM implementations assume rigidity Main techniques used (techniques for monocular non-rigid scenes): isometric shape from template (SfT) non-rigid structure from motion (NRSfM) Main principle: computation in two parallel threads (s. DefSLAM framework) Deformation tracking [front end] Deformation mapping [back end] The map from the mapping thread defines the shape-at-rest template used by deformation tracking Validation: compare with ORBSLAM (rigid) Assumes isometric deformation Future work: relocalisation (s.</description></item><item><title>Lamarca 2020 DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</guid><description>URL: http://arxiv.org/abs/1908.08918 Authors: Lamarca et al Code: http://github.com/UZ-SLAMLab/DefSLAM Results (video): http://www.youtube.com/watch?v=6mmhD2_t6Gs Summary
First monocular SLAM for deformable environments in real-time Most other SLAM implementations assume rigidity Main techniques used (techniques for monocular non-rigid scenes): isometric shape from template (SfT) non-rigid structure from motion (NRSfM) Main principle: computation in two parallel threads (s. DefSLAM framework) Deformation tracking [front end] Deformation mapping [back end] The map from the mapping thread defines the shape-at-rest template used by deformation tracking Validation: compare with ORBSLAM (rigid) Assumes isometric deformation Future work: relocalisation (s.</description></item><item><title>Literature management</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/literature-management/</link><pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/literature-management/</guid><description> Only focus on one paper per topic at a time Skim through and take notes on only the important chapters Link and backlink Note which topics were skimmed Come back later for further literature review</description></item><item><title>Programmatic implementations of MonoSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/programmatic-implementations-of-monoslam/</link><pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/programmatic-implementations-of-monoslam/</guid><description>Parent: SLAM resources Python http://github.com/agnivsen/Py-M-SLAM http://github.com/agnivsen/LibMonoSLAM
MATLAB http://perso.ensta-paris.fr/~filliat/Courses/2011_projets_C10-2/BRUNEAU_DUBRAY_MURGUET/monoSLAM_bruneau_dubray_murguet_en.html</description></item><item><title>Template for a bibliography entry</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/template-for-a-bibliography-entry/</link><pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/template-for-a-bibliography-entry/</guid><description>Source Backlinks
Authors Abstract Contents/Chapters Takeaway</description></item><item><title>(Wu 2018) Image-based camera localization</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wu-2018-image-based-camera-localization-an-overview/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wu-2018-image-based-camera-localization-an-overview/</guid><description>Authors: Wu, Tang, Li
Abstract/Contents
overview (classification) of image-based camera localization classification of image-based camera localization approaches techniques, trends only considers 2D cameras focuses on points as features in images (not lines etc) Chapters Classification of image-based camera localization approaches [Multisensor fusion](multisensor fusion.md) — why use the visual-inertial sensor combination? Loose vs Tight coupling Filter localisation methods Some optimisation-based tightly-coupled multisensor SLAM algorithms Questions
What&amp;rsquo;s a metric map &amp;ndash; normal map (with landmarks, normal distances) as opposed to a topological one Takeaway</description></item><item><title>(Wu 2018) Image-based camera localization</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wu-2018-image-based-camera-localization-an-overview/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wu-2018-image-based-camera-localization-an-overview/</guid><description>Authors: Wu, Tang, Li
Abstract/Contents
overview (classification) of image-based camera localization classification of image-based camera localization approaches techniques, trends only considers 2D cameras focuses on points as features in images (not lines etc) Chapters Classification of image-based camera localization approaches [Multisensor fusion](multisensor fusion.md) — why use the visual-inertial sensor combination? Loose vs Tight coupling Filter localisation methods Some optimisation-based tightly-coupled multisensor SLAM algorithms Questions
What&amp;rsquo;s a metric map &amp;ndash; normal map (with landmarks, normal distances) as opposed to a topological one Takeaway</description></item><item><title>Cometlabs What You Need to Know About SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cometlabs/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cometlabs/</guid><description>Source: http://blog.cometlabs.io/teaching-robots-presence-what-you-need-to-know-about-slam-9bf0ca037553
SLAM chicken and egg problem Position acquisition Multisensor fusion [Sensors (absolute measurements) for measuring distance to landmarks](sensors (absolute measurements)-for-measuring-distance-to-landmarks.md) Mapping representations in robotics Visual SLAM Implementation Framework Feature-based vs direct SLAM workflow Sparse/Feature-based VSLAM Dense/direct VSLAM</description></item><item><title>Cometlabs What You Need to Know About SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cometlabs/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cometlabs/</guid><description>Source: http://blog.cometlabs.io/teaching-robots-presence-what-you-need-to-know-about-slam-9bf0ca037553
SLAM chicken and egg problem Position acquisition Multisensor fusion [Sensors (absolute measurements) for measuring distance to landmarks](sensors (absolute measurements)-for-measuring-distance-to-landmarks.md) Mapping representations in robotics Visual SLAM Implementation Framework Feature-based vs direct SLAM workflow Sparse/Feature-based VSLAM Dense/direct VSLAM</description></item><item><title>Riisgaard SLAM for dummies</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/riisgaard-slam-for-dummies/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/riisgaard-slam-for-dummies/</guid><description>Authors: Søren Riisgaard and Morten Rufus Blas Parent: SLAM resources Abstract:
Tutorial introduction to SLAM, with minimal prerequisites for the understanding of SLAM as explained here Mostly explains a single approach to the steps involved in SLAM Complete solution for SLAM using EKF (extended Kalman filter) Only considers 2D motion, not 3D Chapters
What is SLAM? Overview of SLAM using EKF Hardware Robot Range measurement device SLAM process Step 1: Odometry update Step 2: Reobservation Step 3: Add new landmarks Laser data Odometry data Landmarks Landmark extraction 1.</description></item><item><title>Riisgaard SLAM for dummies</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/riisgaard-slam-for-dummies/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/riisgaard-slam-for-dummies/</guid><description>Authors: Søren Riisgaard and Morten Rufus Blas Parent: SLAM resources Abstract:
Tutorial introduction to SLAM, with minimal prerequisites for the understanding of SLAM as explained here Mostly explains a single approach to the steps involved in SLAM Complete solution for SLAM using EKF (extended Kalman filter) Only considers 2D motion, not 3D Chapters
What is SLAM? Overview of SLAM using EKF Hardware Robot Range measurement device SLAM process Step 1: Odometry update Step 2: Reobservation Step 3: Add new landmarks Laser data Odometry data Landmarks Landmark extraction 1.</description></item><item><title>SLAM resources</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/slam-resources/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/slam-resources/</guid><description>Parent: SLAM Index Theory
Wikipedia SLAM http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation Thrun - Probabilistic Robotics SLAM for dummies Andrew Davison research page at the Department of Computing , Imperial College London about SLAM using vision. Paper 2002 on monocular SLAM SLAM lectures on YouTube http://openslam-org.github.io / Tutorials SLAM summer school SS06: http://www.robots.ox.ac.uk/~SSS06/Website/
Programming Programmatic implementations of MonoSLAM</description></item><item><title>SLAM resources</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/slam-resources/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/slam-resources/</guid><description>Parent: SLAM Index Theory
Wikipedia SLAM http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation Thrun - Probabilistic Robotics SLAM for dummies Andrew Davison research page at the Department of Computing , Imperial College London about SLAM using vision. Paper 2002 on monocular SLAM SLAM lectures on YouTube http://openslam-org.github.io / Tutorials SLAM summer school SS06: http://www.robots.ox.ac.uk/~SSS06/Website/
Programming Programmatic implementations of MonoSLAM</description></item><item><title>Wikipedia SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-slam/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-slam/</guid><description>Source: http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping Parents: SLAM Index , slam-resources Different types of sensors give rise to different SLAM algorithms whose assumptions are most appropriate to the sensors.
At one extreme, visual features provide details of many points within an area &amp;ndash;&amp;gt; rendering SLAM unnecessary shapes in these point clouds can be easily and unambiguously aligned at each step via image registration . At the opposite extreme, tactile sensors are extremely sparse they contain only information about points very close to the agent require strong prior models to compensate in purely tactile SLAM.</description></item><item><title>Wikipedia SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-slam/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-slam/</guid><description>Source: http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping Parents: SLAM Index , slam-resources Different types of sensors give rise to different SLAM algorithms whose assumptions are most appropriate to the sensors.
At one extreme, visual features provide details of many points within an area &amp;ndash;&amp;gt; rendering SLAM unnecessary shapes in these point clouds can be easily and unambiguously aligned at each step via image registration . At the opposite extreme, tactile sensors are extremely sparse they contain only information about points very close to the agent require strong prior models to compensate in purely tactile SLAM.</description></item><item><title>Wikipedia Visual odometry</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-visual-odometry/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-visual-odometry/</guid><description>Source: http://en.wikipedia.org/wiki/Visual_odometry Odometry Visual sensors for localisation</description></item><item><title>Wikipedia Visual odometry</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-visual-odometry/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/wikipedia-visual-odometry/</guid><description>Source: http://en.wikipedia.org/wiki/Visual_odometry Odometry Visual sensors for localisation</description></item><item><title>http://www.sofa-framework.org/applications/gallery/percutaneous-liver-surgery/</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/https-www.sofa-framework.org-applications-gallery-percutaneous-liver-surgery-/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/https-www.sofa-framework.org-applications-gallery-percutaneous-liver-surgery-/</guid><description>http://www.sofa-framework.org/applications/gallery/percutaneous-liver-surgery/ Constraint-based haptic rendering</description></item><item><title>Topological changes during elastic registration</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/topological-changes-during-elastic-registration/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/topological-changes-during-elastic-registration/</guid><description>http://www.sofa-framework.org/applications/gallery/augmented-reality-in-nephrology/
http://www.youtube.com/watch?v=3rfdL3-wWE0</description></item><item><title>SofaPython API/Documentation links</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sofapython-api-documentation-links/</link><pubDate>Fri, 17 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sofapython-api-documentation-links/</guid><description>Parent: SofaPython Index SP2
SofaPython pdf http://www.sofa-framework.org/api/master/plugins/SofaPython/html/index.html http://sofacomponents.readthedocs.io/en/latest/index.html SP3
http://sofapython3.readthedocs.io/en/latest/menu/SofaPlugin.html</description></item><item><title>SOFA Cataract surgery</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-cataract-surgery/</link><pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-cataract-surgery/</guid><description>http://www.sofa-framework.org/applications/gallery/eye-surgery-simulator-insimo/
SOFA – Cataract Surgery – InSimo www.sofa-framework.orgThe SOFA technology is at the core of a advanced eye surgery simulator developed in the context of the HelpMeSee project. HelpMeSee is an American foundation with a singular mission:… read more →</description></item><item><title>SOFA extended documentation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-extended-documentation/</link><pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-extended-documentation/</guid><description>Source: http://hal.inria.fr/hal-00681539 Authors: Faure et al Backlinks: Scope of Studienarbeit Abstract
SOFA: open source C++ library mainly for interactive physical/medical simulation modular approach by decomposing simulators into its constituent components (DOF, differential equations, solvers etc), and organising them in a scenegraph data structure multimodel representation of objects (collision model, visual model etc) Chapters
Read
1: introduction 2: multimodel framework 3: data structures 3.1 scenegraph and visitors 3.</description></item><item><title>SOFA extended documentation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-extended-documentation/</link><pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/sofa-extended-documentation/</guid><description>Source: http://hal.inria.fr/hal-00681539 Authors: Faure et al Backlinks: Scope of Studienarbeit Abstract
SOFA: open source C++ library mainly for interactive physical/medical simulation modular approach by decomposing simulators into its constituent components (DOF, differential equations, solvers etc), and organising them in a scenegraph data structure multimodel representation of objects (collision model, visual model etc) Chapters
Read
1: introduction 2: multimodel framework 3: data structures 3.1 scenegraph and visitors 3.</description></item><item><title>Introduction to the Kalman Filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/introduction-to-the-kalman-filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/introduction-to-the-kalman-filter/</guid><description> http://resourcium.org/journey/introduction-kalman-filter</description></item></channel></rss>