<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>-sa/to-be-processed on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/sa/to-be-processed/</link><description>Recent content in -sa/to-be-processed on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/sa/to-be-processed/index.xml" rel="self" type="application/rss+xml"/><item><title>Baumgarte stabilisation over the SO(3) rotation group for control</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/baumgarte-stabilisation-over-the-so-3-rotation-group-for-control/</guid><description>Author: Sebastien Gros</description></item><item><title>Maley 2013 MEKF for Nonspinning Guided Projectiles</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/maley-2013-mekf-for-nonspinning-guided-projectiles/</guid><description>Source: http://apps.dtic.mil/sti/citations/ADA588831</description></item><item><title>Markley 2003 Attitude Error Representations for Kalman Filtering</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</link><pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markley-2003-attitude-error-representations-for-kalman-filtering/</guid><description>Source: http://scholar.google.com/scholar?cluster=9266330323139560128&amp;amp;hl=en&amp;amp;as_sdt=0,5 Author: FL Markley
Motivation
Quaternion as an attitude representation
Good: lowest dimensionality while being a globally nonsingular representation Not so good: must obey a unit norm constraint In research, various methods for either getting around the norm constraint, or to enforce it
Most successful method employs the global attitude as a unit quaternion with a 3-comp attitude error representation
MEKF doesn&amp;rsquo;t estimate the quaternion state.</description></item><item><title>Diagnosis bladder cancer</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/diagnosis-bladder-cancer/</link><pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/diagnosis-bladder-cancer/</guid><description>http://www.cancer.org/cancer/bladder-cancer/detection-diagnosis-staging/how-diagnosed.html</description></item><item><title>Endoscope tip</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/endoscope-tip/</link><pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/endoscope-tip/</guid><description>Source: &amp;lt;http://www.osapublishing.org/ao/fulltext.cfm?uri=ao-43-1-113&amp;amp;id=78236
F2&amp;gt; Note: this is a mini endoscope, probably not the standard construction</description></item><item><title>Jeon 2009 Kinematic Kalman Filter for Robot End-Effector Sensing</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/jeon-2009-kinematic-kalman-filter-for-robot-end-effector-sensing/</guid><description>Backlinks: Discussion 2021-05-25 Authors: Jeon and Tomizuka
Abstract
inaccuracies in estimation of EE motion can come from kinematic error (error in parameters in kinematic equations)
to overcome this: take direct measurements e.g. using vision, but vision has high latency IMUs are used to provide interframe data fuse camera and IMU in a kinematic Kalman filter (KKF) framework. Note: uses ESKF
effect of camera measurement delay, augmenting the KF states to also estimate the time delay</description></item><item><title>Modified vs original DH</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/modified-vs-original-dh/</link><pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/modified-vs-original-dh/</guid><description>Wikipedia
Modified DH (proximal) Original DH (distal?) a: offset in x (from old origin)alpha: twist of z around old x axisd: offset in z (to next origin)theta: rotation around current z d: offset in z (from prev origin)theta: rotation around prev zr / a: offset in x from prev originalp: twist of z around current x</description></item><item><title>Spherical wrist</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/spherical-wrist/</link><pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/spherical-wrist/</guid><description>http://www1.cs.columbia.edu/~allen/F15/NOTES/forwardspong.pdf
S. also http://www.youtube.com/watch?v=S6TFakW5YcI</description></item><item><title>Cyril Stachniss EKF-SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cyril-stachniss-ekf-slam/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cyril-stachniss-ekf-slam/</guid><description>Links:
Course material: http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/ Lectures: http://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_&amp;amp;feature=g-list</description></item><item><title>IMU to camera coordinate transformations</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/imu-to-camera-coordinate-transformations/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/imu-to-camera-coordinate-transformations/</guid><description>Parent: IMU index Source: Weiss 2011</description></item><item><title>(Weiss Thesis) Vision based navigation for micro helicopters</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/weiss-thesis-vision-based-navigation-for-micro-helicopters/</guid><description>Source Backlinks
Authors Stephan Weiss Abstract
Issues that arise during state estimation and sensor self-calibration Application area: large and unknown areas, micro helicopter Vision based method used uses SfM, is compares mapless and map-based methods Statistical and modular sensor fusion strategy recovery of pose and drifts modular: camera as a black box sensor, allows other sensors additionally Observability analysis Literature review
Fusing IMU with monocular vision: given extrinsic parameters , an IMU is able to recover metric scale, as well as help transition across short vision failure period Armesto et al.</description></item><item><title>Discretising a state space equation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/discretising-a-state-space-equation/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/discretising-a-state-space-equation/</guid><description>Source: [http://en.wikibooks.org/wiki/Control_Systems/State-Space_Equations
Discretization](http://en.wikibooks.org/wiki/Control_Systems/State-Space_Equations Discretization) Discretising a state space equation</description></item><item><title>note quaternions</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/note-quaternions/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/note-quaternions/</guid><description>Converting from quaternion to angular velocity then back to quaternion http://math.stackexchange.com/questions/2282938/converting-from-quaternion-to-angular-velocity-then-back-to-quaternion</description></item><item><title>resource IMU common specifications, error models etc</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/resource-imu-common-specifications-error-models-etc/</link><pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/resource-imu-common-specifications-error-models-etc/</guid><description>Parent: IMU Source: http://www.vectornav.com/resources/imu-specifications
IMU common specifications, bias, scale factor, orthogonality errors, and acceleration sensitivity for gyroscopes.
Source: Woodman - An introduction to inertial navigation Source: Quinchia - A Comparison between Different Error Modeling of MEMS Applied to GPS/INS Integrated Systems
3.2. State-Space Representation for Different Bias Models
First order Gauss-Markov (GM) Random walk Autoregressive process</description></item><item><title>note KF with missing measurements</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/note-kf-with-missing-measurements/</link><pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/note-kf-with-missing-measurements/</guid><description>Sources http://math.stackexchange.com/questions/982982/kalman-filter-with-missing-measurement-inputs http://opencv-users.1802565.n2.nabble.com/Kalman-filters-and-missing-measurements-td2886593.html
For a missing measurement:
use the last state estimate as a measurement set the covariance matrix of the measurement to essentially infinity. This would cause a Kalman filter to essentially ignore the new measurement since the ratio of the variance of the prediction to the measurement is zero. The result will be a new prediction that maintains velocity/acceleration but whose variance will grow according to the process noise.</description></item><item><title>note KF with different sampling rate</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/note-kf-with-different-sampling-rate/</link><pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/note-kf-with-different-sampling-rate/</guid><description>Source: http://stackoverflow.com/questions/59566384/kalman-filter-with-different-sampling-rate
Approach 1: KF with variable dt Approach 2: KF with static dt
&amp;lsquo;Sub&amp;rsquo; updates? e.g.
predict() update() with sensor A skip update() for sensor B since no measurement arrived update() with sensor c repeat Generally discouraged:
If not predicting before each update, there is the risk of the filter lagging behind real world dynamics. The update step at t=k compares a measurement zk to the projected (predicted) state xk.</description></item><item><title>IMU motion model (discrete)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/imu-motion-model-discrete/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/imu-motion-model-discrete/</guid><description>Parent: [IMU index](imu index.md), probabilistic models-for-imu Source: [MKok 2017 Using inertial sensors for position and orientation estimation](mkok 2017 using inertial sensors-for-position-and-orientation-estimation.md)
Position dynamics Orientation dynamics (either quaternion or rotation matrix representation) with</description></item><item><title>MKok 2017 Using inertial sensors for position and orientation estimation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mkok-2017/</guid><description>Source: http://arxiv.org/abs/1704.06053 Authors: M Kok, JD Hol, TB Schön
Abstract
Contents/Chapters Quaternions Probabilistic models for IMU Orientation parametrisations Which orientation parametrisation to choose? Linearisation of an orientation in SO(3) IMU measurement model Modelling noise and bias for IMU IMU motion models IMU prior models</description></item><item><title>On quaternions and rotation matrices</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/on-quaternions-and-rotation-matrices/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/on-quaternions-and-rotation-matrices/</guid><description>http://stackoverflow.com/questions/8919086/why-are-quaternions-used-for-rotations
It&amp;rsquo;s worth bearing in mind that all the properties related to rotation are not truly properties of Quaternions: they&amp;rsquo;re properties of Euler-Rodrigues Parameterisations, which is the actual 4-element structure used to describe a 3D rotation. Their relationship to Quaternions is purely due to a paper by Cayley, &amp;ldquo;On certain results related to Quaternions&amp;rdquo;, where the author observes the correlation between Quaternion multiplication and combination of Euler-Rodrigues parameterisations. This enabled aspects of Quaternion theory to be applied to the representation of rotations and especially to interpolating between them.</description></item><item><title>DBoW2 weighing and scoring</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/dbow2-weighing-and-scoring/</guid><description>Source: http://github.com/dorian3d/DBow</description></item><item><title>Intro to bladder cancer</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/intro-to-bladder-cancer/</link><pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/intro-to-bladder-cancer/</guid><description>http://www.cancer.net/cancer-types/bladder-cancer/introduction</description></item><item><title>MAP estimation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/map-estimation/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/map-estimation/</guid><description>Source: Forster 2017 IMU Preintegration Factor graph: way of representing the posterior probability of the states given the available measurements and priors The terms in the equation above are called &amp;lsquo;factors&amp;rsquo;
MAP: maximum a posteriori We want to maximise the probability derived above &amp;ndash;&amp;gt; MAP estimate (aka minimum of negative log posterior) The negative log posterior can be written as a sum of squared residuals, assuming zero-mean Gaussian noise residual errors (prior, IMU, camera) covariance matrices How do we define these residuals?</description></item><item><title>Non-rigid monocular techniques in the literature</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/non-rigid-monocular-techniques-in-the-literature/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/non-rigid-monocular-techniques-in-the-literature/</guid><description>Source: Lamarca 2019 DefSLAM SfT methods
require: 1 monocular image 1 textured shape at rest (template) &amp;ldquo;geometry&amp;rdquo; as the deformation model different definitions of the deformation model analytic, e.g. isometric deformation-based: assumes preserved geodesic distance between surface points isometry for SfT has proven to be well-posed &amp;ndash;&amp;gt; led to stable, real-time solutions energy-based; jointly minimises {energy shape w.r.t. template [shape at rest] + reprojection error for image correspondences} classification according to [ http://www.</description></item><item><title>Grisetti 2011 - Tutorial graph-based SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/grisetti-2011/</guid><description>temp
Backlinks: What is SLAM? Abstract
formulate SLAM using a graph nodes: poses of the robot (as well as landmark postiions) at different points in time edges: constraints between poses come from sensor measurements/observations robot movement/control input constraints can contradict each other, due to effect of noise in sensor readings solve the graph, i.e. compute the map: find the spatial configuration of the nodes that best satisfy the constraints/edges tutorial for back-end (optimisation) part of graph-based SLAM :: Navigation task: requires a map and knowledge of current position relative to locations in the map</description></item><item><title>Badias 2020 MORPH-DSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/badias-2020-morph-dslam/</guid><description>URL: http://arxiv.org/pdf/2009.00576.pdf Video: http://www.youtube.com/watch?v=P_QN8Nv&amp;ndash;_g To read!</description></item><item><title>Preintegration of IMU</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/preintegration-of-imu/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/preintegration-of-imu/</guid><description>Parent: IMU Backlinks: IMU states, dynamics equations IMU measurements arrive at a higher frequency (frame rate) compared to camera captures (keyframe rate) IMU measurements constrain consecutive states We want to summarise these &amp;lsquo;in-between&amp;rsquo; IMU measurements into one single relative motion constraint between keyframes</description></item><item><title>Tracking in VIORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</guid><description>Source: Mur-Artal 2017 VI-ORB Tracking in VIORB
Visual-inertial tracking at frame rate, instead of using an ad-hoc motion model as in the original ORB-SLAM Tracked states: [sensor pose (R, p), velocities v, biases b] Once the camera pose is predicted, map points are projected, then matches with existing features on the frame Then optimise the current frame j, depending on whether the map has just been updated the map is unchanged Here, the optimisation function for tracking (when map unchanged) is:</description></item><item><title>OptiTrack in SOFA</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/optitrack-in-sofa/</link><pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/optitrack-in-sofa/</guid><description> Using OptiTrackNatNet C++ implementation? http://www.sofa-framework.org/community/doc/programming-with-sofa/create-your-scene-in-cpp/ XML scenes? OptiTrack + Python otnn_client = root.addObject(&amp;lsquo;OptiTrackNatNetClient&amp;rsquo;, name=&amp;lsquo;otnnClient&amp;rsquo;) &amp;lt;Sofa.Core.Object&amp;gt; dir(otnn_client) [&amp;lsquo;bbox&amp;rsquo;, &amp;lsquo;clientName&amp;rsquo;, &amp;lsquo;componentState&amp;rsquo;, &amp;lsquo;drawOtherMarkersColor&amp;rsquo;, &amp;lsquo;drawOtherMarkersSize&amp;rsquo;, &amp;lsquo;drawTrackedMarkersColor&amp;rsquo;, &amp;lsquo;drawTrackedMarkersSize&amp;rsquo;, &amp;lsquo;listening&amp;rsquo;, &amp;lsquo;name&amp;rsquo;, &amp;lsquo;otherMarkers&amp;rsquo;, &amp;lsquo;printLog&amp;rsquo;, &amp;lsquo;scale&amp;rsquo;, &amp;lsquo;serverName&amp;rsquo;, &amp;lsquo;tags&amp;rsquo;, &amp;lsquo;trackedMarkers&amp;rsquo;] bold: not in API http://www.sofa-framework.org/api/master/plugins/OptiTrackNatNet/html/class_sofa_opti_track_nat_net_1_1_opti_track_nat_net_client.html difference between client name and server name</description></item><item><title>Someone's SP3 setup</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/someones-sp3-setup/</link><pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/someones-sp3-setup/</guid><description>Parent: SofaPython Index http://gist.github.com/pedroperrusi/9fdd4257db72465c8fb481381f396c51</description></item><item><title>50.2.30 Multivariate Kalman filter algorithm</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.30-multivariate-kalman-filter-algorithm/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.30-multivariate-kalman-filter-algorithm/</guid><description>Parent: Multivariate Kalman filters Source: rlabbe Kalman/Bayesian filters in Python Initialisation
Initialise filter state Initialise belief in the state Predict
Propagate state to the next time step using the system model [prediction] Adjust belief to take into account the prediction uncertainty [prior] Update
Obtain measurement and associated belief about its accuracy Calculate residual (prior - measurement) Calculate scaling factor/Kalman gain Set estimated state to be on the residual line based on the scaling factor Update the belief in the state based on measurement certainty Designing the measurement function</description></item><item><title>Hidden variables in a multivariate Kalman filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/hidden-variables-in-a-multivariate-kalman-filter/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/hidden-variables-in-a-multivariate-kalman-filter/</guid><description>Parent: Multivariate Kalman filters Source: rlabbe Kalman/Bayesian filters in Python Example: Blue error ellipse:
Certainty in position x=0 No idea about the velocity (long in y-axis) We know that position and velocity are correlated, i.e. the next position depends on the current velocity value (red error ellipse — likelihood/prediction for the next step) e.g. if v=5m/s, the next position is 5m +- position uncertainties
We get a position update (new blue error ellipse) The new covariance (posterior) is obtained by multiplying the previous two covariances —&amp;gt; intersection The posterior&amp;rsquo;s tilt implies that there is some correlation between position and velocity Not only are we now more certain about the velocity, but our position certainty also increases (compared to not considering the velocity at all)!</description></item><item><title>Multivariate Kalman filters</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-kalman-filters/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-kalman-filters/</guid><description>Parent: rlabbe Kalman/Bayesian filters in Python [Hidden variables in a multivariate Kalman filter](hidden variables-in-a-multivariate-kalman-filter.md)
Here:
Focus is on a subset of problems describable using Newton&amp;rsquo;s equations of motion Discretised continuous-time kinematic filters Multivariate Kalman filter algorithm Designing the filter
State (x, P) Process (F, Q) Measurement (z, R) Measurement function H Control inputs (B, u) Assumptions of the Kalman filter
The sensors and motion model have Gaussian noise Everything is linear If the assumptions are true, then the Kalman filter is optimal in a least squares sense</description></item><item><title>50.2.20 1D Kalman filters</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.20-1d-kalman-filters/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.20-1d-kalman-filters/</guid><description>Source: rlabbe Kalman/Bayesian filters in Python [Deriving Kalman filter from Discrete Bayes using Gaussians](deriving kalman filter-from-discrete-bayes-using-gaussians.md) 1D Kalman filter algorithm Kalman gain using Gaussians Variance of the 1D Kalman filter Factors affecting Kalman filter performance</description></item><item><title>50.2.20.1 1D Kalman filter algorithm</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.20.1-1d-kalman-filter-algorithm/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/50.2.20.1-1d-kalman-filter-algorithm/</guid><description>Parent: 1D Kalman filters Source: rlabbe Kalman/Bayesian filters in Python Initialisation:
Initialise the state of the filter Initialise the belief in the state Predict step:
Gaussian addition prior = predict(x, process_model) Incorporate process variance in order to prevent smug filtering Update step:
Gaussian multiplication likelihood = gaussian(z, sensor_var) x = update(prior, likelihood) The output of both steps is a Gaussian probability distribution N(mean, var)</description></item><item><title>Gaussian distribution</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/gaussian-distribution.1/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/gaussian-distribution.1/</guid><description>Backlinks: Limitations of the discrete Bayes filter Source: rlabbe Kalman/Bayesian filters in Python a.k.a. Normal distribution Unimodal, continuous probability distribution function (pdf)
The probability of a range of measurements is the area under the graph of the probability distribution between the end values of the range &amp;ndash; cumulative distribution function (cdf)
Background statistics Variance, standard deviation, covariances Central Limit Theorem Correlation and independence Types Univariate Gaussian distribution Multivariate Gaussian distributions Computational properties of Gaussian distributions Pros and cons of Gaussian distributions</description></item><item><title>Kalman gain using Gaussians</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/kalman-gain-using-gaussians/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/kalman-gain-using-gaussians/</guid><description>Parent: 1D Kalman filters Source: rlabbe Kalman/Bayesian filters in Python Kalman gain in the update step Basically a scaling term that chooses a value between the sensor distr. mean and the posterior distr. mean Gives greater weight to the term with lower variance (we trust this data more!) Mean and variance in terms of the Kalman gain Variance of the filter (i.e., what variance is show by the estimated output/posterior?</description></item><item><title>Multivariate Gaussian distributions</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-gaussian-distributions/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-gaussian-distributions/</guid><description>Parent: Gaussian distribution Source: rlabbe Kalman/Bayesian filters in Python See also: Probability distribution N means for N dimensions Variances are now also combined with covariances (to take into account correlation between different dimensions)
Variance: how does a population vary amongst themselves? Covariance: how much do two variables change relative to each other? The correlation helps prediction!
Here: only linear correlation considered; however nonlinear correlations also exist.
Error ellipse/Confidence ellipse</description></item><item><title>Cadena 2016 Past, Present, and Future of SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cadena-2016/</guid><description>Authors Cadena et al
Abstract
cited by 1.2k people &amp;ldquo;This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM&amp;rdquo; Recommended other works s. Works of possible interest Contents/Chapters Takeaway</description></item><item><title>Durrant-Whyte 2006 SLAM Tutorial Part I</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/durrant-whyte-2006-slam-tutorial-part-i/</guid><description>Backlinks: Works of possible interest Authors: Bailey, Durrant-Whyte
Abstract:
Contents/Chapters
Takeaway</description></item><item><title>Chen 2018 SLAM-based dense surface reconstruction in MIS with AR</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/chen-2018-mis-slam/</guid><description>Authors Chen et al
Abstract
Intra-operative dense surface reconstruction framework to provide geometry information from only monocular videos The proposed framework works well with rapid camera movements, however is not suitable for large deformations Only tweaks ORBSLAM to adjust between point density and computational performance Contents/Chapters Problems in medical AR:
tissue surface illumination tissue deformation rapid movements of the medical tool e.g. endoscope (s. also kidnapped robot problem for relocalisation, tracking mus therefore be robust) field of view often very small &amp;ldquo;A typical human uses 14 visual cues to perceive depth, only 3/14 are binocular vision related.</description></item><item><title>Song 2018 MIS-SLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/song-2018-mis-slam/</guid><description>Authors Song et al Backlinks: referred to in Lamarca 2019 as a stereovisual deformable SLAM, uses CPU and GPU, nonlinear optimisation Video: http://www.youtube.com/watch?v=2pXokldQBWM
Abstract
Uses CPU and GPU CPU for ORBSLAM (initial global position) GPU for deformable tracking and dense mapping Contents/Chapters
Poor localisation of scope in MIS, compared with open surgery Related works mentioned don&amp;rsquo;t provide a RT and robust solution for localisation while reconstructing dense deformable surfaces focus on the monocular scope, fail to solve the problem of missing scale Fast movement makes visual odometry unstable causes blurry images worsens registrations ORB-SLAM proven to be suitable for coupling with dense deformable SLAM Initial tracking: ORB-SLAM</description></item><item><title>Qin 2019 General Optimization-based Framework (Multisensor)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/qin-2019-general-optimization-based-framework-multisensor/</guid><description>Authors: Qin et al Code: http://github.com/HKUST-Aerial-Robotics/VINS-Fusion (uses ROS)
Abstract:
odometry estimation with multiple sensors, general framework which is optimisation-based demonstrated combinations: stereo cameras monocular cam + IMU stereo cams + IMU sensor = factor in the framework comparison with other state-of-the-art algos Aim:
to create a general algo which supports different multisensor suites also for redundancy: in case of sensor failure, it can be switched out easily Related work:</description></item><item><title>Introduction to the Kalman Filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/introduction-to-the-kalman-filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/introduction-to-the-kalman-filter/</guid><description> http://resourcium.org/journey/introduction-kalman-filter</description></item></channel></rss>