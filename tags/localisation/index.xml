<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>localisation on</title><link>https://salehahr.github.io/tags/localisation/</link><description>Recent content in localisation on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 20 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://salehahr.github.io/tags/localisation/index.xml" rel="self" type="application/rss+xml"/><item><title>Data association in DefSLAM</title><link>https://salehahr.github.io/studienarbeit/data-association-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/data-association-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM See also: Data association Goal: match keypoints in current frame (newly extracted) with map points (already in map/system) Use the active matching strategy proposed in [Agudo 2015]: “Simultaneous pose and non-rigid shape with particle dynamics,” Steps  ORB points (keypoints) are detected in current frame
Camera pose Tcw is predicted
using camera motion model camera motion model: function of past camera poses Predict where map points (existing in map) would be imaged, based on last estimated template i.</description></item><item><title>Covisible keyframes</title><link>https://salehahr.github.io/studienarbeit/covisible-keyframes/</link><pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/covisible-keyframes/</guid><description>Source: Palafox 2019 ( thesis ) Backlinks: Lamarca 2019 DefSLAM Two keyframes are covisible if they share several common landmarks.</description></item><item><title>Egomotion (vs odometry)</title><link>https://salehahr.github.io/studienarbeit/egomotion-vs-odometry/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/egomotion-vs-odometry/</guid><description>See also: Odometry Source: http://en.wiktionary.org/wiki/egomotion The three-dimensional movement of a camera relative to its environment
Source: http://answers.ros.org/question/296686/what-is-the-differences-between-ego-motion-and-odometry/
Generally used interchangeably with odometry Possible difference: Egomotion is more about the estimation of twist (lin, rotational velocities) Odometry is more about the estimation of path Examples
Wheel odometry: path estimation via time-integration of an estimated twist Visual odometry/Scan matching: direct estimation of pose without time-integration</description></item><item><title>Wikipedia Lokalisierung</title><link>https://salehahr.github.io/studienarbeit/wikipedia-lokalisierung/</link><pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/wikipedia-lokalisierung/</guid><description>Source: http://de.wikipedia.org/wiki/Lokalisierung_(Robotik Localisation Particle filters Categories of sensors for localisation</description></item><item><title>Distance between landmarks</title><link>https://salehahr.github.io/studienarbeit/distance-between-landmarks/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/distance-between-landmarks/</guid><description>Source: SLAM for Dummies Backlinks: Nearest Neighbour Methods:
Euclidean distance (suitable for far distances) Mahalanobis distance (better, but more complex)</description></item><item><title>Landmark extraction</title><link>https://salehahr.github.io/studienarbeit/landmark-extraction/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/landmark-extraction/</guid><description>Source: SLAM for Dummies Backlinks: Basic EKF for SLAM , nearest-neighbour Basic landmark extraction using a laser scanner
Spike algorithm RANSAC ( ekf handles points) Expansion of RANSAC so that EKF handles lines Scan-matching: two successive laser scans are matched Spike and RANSAC are good for indoor environments</description></item><item><title>Nearest Neighbour</title><link>https://salehahr.github.io/studienarbeit/nearest-neighbour/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/nearest-neighbour/</guid><description>Source: SLAM for Dummies Backlinks: Data association Nearest neighbour approach
Get a new laser scan &amp;ndash;&amp;gt; ( landmark extraction ) extract all visible landmarks Associate each extracted LM to the closest LM we have seen more than N times Pass each pairs of association (extracted LM, LM in database) through a validation gate If pair passes &amp;ndash;&amp;gt; n = n + 1 (num. times seen) If pair fails &amp;ndash;&amp;gt; add new LM to database, with n := 1</description></item><item><title>Validation gate</title><link>https://salehahr.github.io/studienarbeit/validation-gate/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/validation-gate/</guid><description>Source: SLAM for Dummies Backlinks: Nearest Neighbour An observed landmark is associated to a landmark if the following holds v innovation S innovation covariance The Validation gate makes use of the fact that the EKF implementation gives a bound on the uncertainty of an observation of a LM
Is an observed LM a LM in the database?</description></item><item><title>Key frames in loop closure detection</title><link>https://salehahr.github.io/studienarbeit/key-frames-in-loop-closure-detection/</link><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/key-frames-in-loop-closure-detection/</guid><description>Source: cometlabs Backlinks: Loop closure detection Most common method to get candidate key frames: use a place recognition approach
approach based on vocab tree feature descriptors of candidate key frames are quantised one colour in image below corresponds to one feature descriptor/&amp;lsquo;vocabulary&amp;rsquo; each point is a &amp;lsquo;word&amp;rsquo; that belongs to a vocabulary the words can then be counted and put into a frequency histogram the histogram is used to compare similarity of images I think similar images then get filtered out, so we get key frames</description></item><item><title>Kidnapped robot problem</title><link>https://salehahr.github.io/studienarbeit/kidnapped-robot-problem/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/kidnapped-robot-problem/</guid><description>Source: Wikipedia Lokalisierung Backlinks: Lamarca 2020 DefSLAM Position initially known Then robot is repositioned without knowing it Robot has to be able to realise that the initial successful localisation isn&amp;rsquo;t valid any more &amp;ndash; a new global localisation must be carried out Realise this via unplausible sensor measurements (huge contradiction to prev. measurements) Has to do with the measure of robustness of the localisation method carried out</description></item><item><title>Mapping representations in robotics</title><link>https://salehahr.github.io/studienarbeit/mapping-representations-in-robotics/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/mapping-representations-in-robotics/</guid><description>Source: [Cometlabs What You Need to Know About SLAM](cometlabs what you-need-to-know-about-slam.md)
Feature maps Occupancy grids Grids containing occupancy probability information Useful for path planning, exploration Drawback: computational complexity</description></item><item><title>Step 3 New landmarks</title><link>https://salehahr.github.io/studienarbeit/step-3-new-landmarks/</link><pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/step-3-new-landmarks/</guid><description>Source: SLAM for Dummies Backlinks: Basic EKF for SLAM Overview
Landmarks that are new are not dealt with until step 3. Delaying the incorporation of new landmarks until the will decrease the computation cost needed for this step the covariance matrix, P, and the system state, X, are smaller by then. Update state vector x and covariance matrix P with new landmarks Add new landmark to state vector X Add new row and column to covariance matrix Covariance for new landmark Robot-landmark covariance</description></item><item><title>Data association</title><link>https://salehahr.github.io/studienarbeit/data-association/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/data-association/</guid><description>Parents: SLAM Index , basic-ekf-for-slam Source: SLAM for Dummies Backlinks: [What is SLAM?](what is slam_.md), [data association in defslam](data association in defslam.md), visual slam-implementation-framework Matching observed landmarks from different scans (different time steps) with each other. Also called &amp;rsquo;re-observing' landmarks.
Problems that can arise:
The landmark(s) might not be observed every time step (bad landmark) Something might be observed as a landmark, but it never appears again (bad landmark) Wrong association of a landmark to a previously seen landmark Goal: define a suitable data-association policy to minimise the first two problems Given: database that stores previously seen landmarks (initially empty) As a rule: a landmark is only considered worthwhile to be used in SLAM once it is seen N times</description></item><item><title>Spike landmarks</title><link>https://salehahr.github.io/studienarbeit/spike-landmarks/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/spike-landmarks/</guid><description>Source: SLAM for Dummies Backlinks: Landmark extraction Uses extrema to find landmarks Find values in the range of a laser scan, where two values differ by more than a certain amount (e.g. 0.5 m) This finds big changes in the laser scan Alternatively, using three values next to each other: A, B, C (A - B) + (C - B) yields a value Better for finding spikes as it finds actual spikes Rely on the landscape changing a lot between two laser beams Algo will fail in smooth environments Suitable for indoor environments, however is not robust against envs w/ people people are picked up as spikes as theoretically they are good landmarks (just not stationary!</description></item><item><title>Wikipedia Visual odometry</title><link>https://salehahr.github.io/studienarbeit/wikipedia-visual-odometry/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/wikipedia-visual-odometry/</guid><description>Source: http://en.wikipedia.org/wiki/Visual_odometry Odometry Visual sensors for localisation</description></item><item><title>Wikipedia Visual odometry</title><link>https://salehahr.github.io/studienarbeit/wikipedia-visual-odometry/</link><pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/studienarbeit/wikipedia-visual-odometry/</guid><description>Source: http://en.wikipedia.org/wiki/Visual_odometry Odometry Visual sensors for localisation</description></item></channel></rss>