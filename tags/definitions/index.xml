<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>-definitions on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/definitions/</link><description>Recent content in -definitions on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Thu, 12 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://salehahr.github.io/zettelkasten/tags/definitions/index.xml" rel="self" type="application/rss+xml"/><item><title>bayes-rule</title><link>https://salehahr.github.io/zettelkasten/math/statistics/bayes-rule/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/bayes-rule/</guid><description>Parent: probability-theory Bayes rule Source: blitzstein-hwang $$P(A|B) = \dfrac{P(B|A) P(A)}{P(B)}$$
Extra conditioning &amp;ldquo;Everything is conditioned on $C$.&amp;rdquo;
$$P(A|B, C) = \dfrac{P(B|A, C) P(A|C)}{P(B | C)}$$ given $P(A\cap E) &amp;gt; 0$ and $P(B\cap E) &amp;gt; 0$.
Alternative approaches for interpretation
$B, ~C$ as a single event $B\cap C$
$$P(A|B,C) = \dfrac{P(A, B, C)}{P(B, C)}$$ Swap roles of $B$ and $C$ $$P(A|B, C) = \dfrac{P(C|A, B) P(A|B)}{P(C | B)}$$</description></item><item><title>conditional-probability</title><link>https://salehahr.github.io/zettelkasten/math/statistics/conditional-probability/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/conditional-probability/</guid><description>Parent: probability-theory Conditional probability Source: blitzstein-hwang $$P(A|B) = \dfrac{P(A~\cap~B)}{P(B)}$$
Notation Description $P(A)$ prior held belief $B$ evidence that is observed $P(A\lvert B)$ posterior (updated belief) Properties $0 \leq P(A|B) \leq 1$ $P(\Omega|E) = 1$, $P(\emptyset | E) = 0$ For disjoint events $A_i$, $P(\bigcup_i A_i | E) = \sum_i P(A_i|E)$ Complement: $P(A^c | E) = 1 - P(A|E)$ Union: $P(A\cup B|E) = P(A|E) + P(B|E) - P(A\cap B|E)$</description></item><item><title>Event</title><link>https://salehahr.github.io/zettelkasten/definitions/event/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/event/</guid><description>Parent: probability-theory See also: random-variable Event $E$ Source: Wiki $$E = \left{ \omega_i \right} \subseteq \Omega$$
Group of outcomes Every event $E$ is assigned a probability of it happening Example event: $E = \left{ \omega \in \Omega \mid X(\omega) \leq x \right}$
&amp;ldquo;Set of all outcomes $\omega$ which satisfy the condition $X(\omega) \leq x$&amp;rdquo; $$P(E) = P(X \leq x) = p_E$$ Example Experiment: flip a coin twice $$\Omega = \left{ (H, H), (H, T), (T, H), (T, T) \right}$$</description></item><item><title>naive-probability</title><link>https://salehahr.github.io/zettelkasten/math/statistics/naive-probability/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/naive-probability/</guid><description>Naive probability Source: blitzstein-hwang Let event $A \subseteq \Omega$ $$ P_\text{naive}(A) = \dfrac{|A|}{|\Omega|} $$ where $|A|$ is the number of elements ( outcomes in $A$).
Required assumptions The sample space $\Omega$ is finite. The outcomes $\omega \in \Omega$ have equal probability of happening each. Usage Problems with equally likely outcomes. Problems with symmetry $\rightarrow$ equally likely probabilities for all outcomes
e.g. flipping a fair coin As a null model (as a hypothesis)</description></item><item><title>Outcome</title><link>https://salehahr.github.io/zettelkasten/definitions/outcome/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/outcome/</guid><description>Parent: probability-theory Outcome $\omega$ Source: Wiki Result of a single run of an experiment . Element of the sample space $\Omega$
$$\omega \in \Omega$$</description></item><item><title>probability-function</title><link>https://salehahr.github.io/zettelkasten/math/statistics/probability-function/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/probability-function/</guid><description>Parent: probability-theory Probability function Source: blitzstein-hwang Maps an event $E$ to probability values.
The probability function $P$ must satisfy the axioms:
$P(\emptyset)=0$, $P(\Omega)=1$ $P\left(, \bigcup_i A_i ,\right) = \sum_i P(A_i)$ if the events $A_i$ are mutually exclusive. Properties $P(A^c) = 1 - P(A)$ If $A \subseteq B$, then $P(A) \leq P(B)$ $P(A~\cup~B) = P(A) + P(B) - P(A~\cap~B)$</description></item><item><title>sample-space</title><link>https://salehahr.github.io/zettelkasten/definitions/sample-space/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/sample-space/</guid><description>Parent: probability-theory Sample space Source: blitzstein-hwang Sample space of an experiment :
Set of all possible outcomes $\omega$ of the experiment. Notation: $S$, $\Omega$
$$S = \left{ s_i \right} ~ \forall,i$$ $$\Omega = \left{ \omega_i \right} ~ \forall,i$$ Contains event subsets</description></item><item><title>Probability mass function</title><link>https://salehahr.github.io/zettelkasten/math/statistics/probability-mass-function/</link><pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/probability-mass-function/</guid><description>Backlinks: Experiments in probability theory Probability mass function Source: Wiki Each outcome $\omega$ in the sample space $\Omega$ is assigned a probability value via the probability mass function $p(\omega)$ with the properties $$ \begin{align} p(\omega) &amp;amp;\in \left[ 0, 1\right] \quad \forall, \omega \in \Omega\
\sum_{\omega \in \Omega} p(\omega) &amp;amp;= 1 \end{align} $$
Source: Yang
$X$ is distributed according to the distribution $P$, $$X \sim P(x) ~.$$
For a specific instance of $X$ (or outcome), evaluating the pmf gives the probability $$P(X = x_i) = P(x_i) = p_i \geq 0$$</description></item><item><title>Untitled 1</title><link>https://salehahr.github.io/zettelkasten/definitions/probability-experiment/</link><pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/probability-experiment/</guid><description>Parent: probability-theory See also: Random variable Experiment/Probability space Source: Wiki procedure that can be infinitely repeated has a well-defined sample space constituents: $\Omega$: sample space $\mathcal{F}$ set of events $E$ $$\mathcal{F} = \left{ E_j \right} ~ \forall,j$$ $P$: probability measure function that maps events to probabilities (s. probability mass function ) $$P(E) = p_E$$</description></item><item><title>heap</title><link>https://salehahr.github.io/zettelkasten/embedded/heap/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/embedded/heap/</guid><description>Source: samek-embedded Region of RAM for dynamic memory allocation using malloc() and free(). Not typically used in real time embedded programming.</description></item><item><title>interrupts</title><link>https://salehahr.github.io/zettelkasten/embedded/interrupts/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/embedded/interrupts/</guid><description>Source: samek-embedded Allows processor to abruptly change flow of control Upon interrupting: A hardware in the processor changes the value of the PC (program counter) register The interrupt service routine (ISR) is executed After the ISR ends, the processor resumes execution of the original code</description></item><item><title>stack</title><link>https://salehahr.github.io/zettelkasten/embedded/stack/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/embedded/stack/</guid><description>Source: samek-embedded Stack Area of RAM that can grow or shrink from one end. Analogous to a stack of dishes: new data/dishes can only be added to the top, and data/dishes can only be taken away from the top. In ARM , the stack grows towards the lower addresses. Pointed to by the stack pointer . Initial values of the stack are random, therefore it is important, in function calls, to initialise variables correctly.</description></item><item><title>clock gating</title><link>https://salehahr.github.io/zettelkasten/embedded/clock-gating/</link><pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/embedded/clock-gating/</guid><description>Source: samek-embedded Clock gating Blocks the clock signal to certain parts of the chip Saves power</description></item><item><title>instructions</title><link>https://salehahr.github.io/zettelkasten/embedded/instructions/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/embedded/instructions/</guid><description> Instructions are e.g. commands such as STORE, ADD, SUBTRACT, branch instructions . The instructions are stored in memory addresses. The values stored at the corresponding addresses encode the instruction to be carried out.</description></item><item><title>hyperparameters</title><link>https://salehahr.github.io/zettelkasten/ma/hyperparameters/</link><pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/hyperparameters/</guid><description>Source: Wikipedia Parameters to control the process of learning the model, as opposed to being parameters of the model, which are to be learned.
Subsets:
model hyperparameters (for model selection), e.g. size of the NN topology of the NN algorithm hyperparameters (affect the efficiency of the learning process), e.g. learning rate batch size Source: google-ml-course Learning rate $\alpha$ Regularisation rate $\lambda$ Embedding dimensions</description></item><item><title>batch</title><link>https://salehahr.github.io/zettelkasten/definitions/batch/</link><pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/batch/</guid><description>See also: batching-in-ml Source: google-ml-course Batch Number of data points used to calculate the gradient in a single iteration</description></item><item><title>convex-problems</title><link>https://salehahr.github.io/zettelkasten/ma/convex-problems/</link><pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/convex-problems/</guid><description>Source: google-ml-course A convex function is shaped like this with respect to its parameters:
Convex problems only have one minimum (where the gradient is zero) &amp;ndash;&amp;gt; global minimum.</description></item><item><title>ml-terminology</title><link>https://salehahr.github.io/zettelkasten/ma/ml-terminology/</link><pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/ml-terminology/</guid><description>Source: google-ml-course ML Terminology Term Symbol Description Output, label $\mathbf{y}$ Variable to be predicted Features $\left\lbrace \mathbf{x}_1, \dots, \mathbf{x}_n \right\rbrace$ Representation of the (input) data Model $f: \mathbf{x} \rightarrow \mathbf{y}'$ Mapping of the input to the predictions $\mathbf{y}'$ Weights $\mathbf{w}$ Parameters of the model Term Description Training Process of determining the model parameters (weights) that will allow an accurate mapping of the input to the resulting output (prediction) i.</description></item><item><title>differentiable-rendering</title><link>https://salehahr.github.io/zettelkasten/ma/differentiable-rendering/</link><pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/ma/differentiable-rendering/</guid><description>Source: https://pytorch3d.org/docs/renderer
&amp;ldquo;Differentiable rendering is a relatively new and exciting research area in computer vision, bridging the gap between 2D and 3D by allowing 2D image pixels to be related back to 3D properties of a scene.&amp;rdquo;</description></item><item><title>Identity of a group</title><link>https://salehahr.github.io/zettelkasten/math/rotations/identity-of-a-group/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/identity-of-a-group/</guid><description>Source: https://vladimirbozovic.net/univerzitet/wp-content/uploads/2010/11/group-theory-chapter.pdf
In every group, there is an element $E$, such that $$EA = AE = A$$ for every member $A$ of the group.</description></item><item><title>Sensor fusion</title><link>https://salehahr.github.io/zettelkasten/sensors/sensor-fusion/</link><pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/sensors/sensor-fusion/</guid><description>Source: Phil&amp;rsquo;s Lab Definition Combine multiple sensor readings to form an improved estimate of a desired variable.
Why sensor fusion? Overcome limitations of individual sensors (noise, uncertainty) Estimate quantities that are not directly measurable
e.g. gyroscope measures angular rates of change but can&amp;rsquo;t directly measure roll and pitch angle Fusion in IMU Accelerometer only: good estimate in non-accelerating conditions Gyroscope only: good estimate over short periods of time (due to integration of bias terms)</description></item><item><title>Exponential map</title><link>https://salehahr.github.io/zettelkasten/math/rotations/exponential-map/</link><pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/exponential-map/</guid><description>Parents: Quaternion index , Rotations / SO(3) group index Notation Variables $$\begin{alignedat}{3} &amp;amp;\phi &amp;amp;&amp;amp;\in \mathbb{R}^3\
&amp;amp;\phi^\wedge &amp;amp;&amp;amp;\in \mathfrak{so}(3)\
&amp;amp;\mathbf{R} &amp;amp;&amp;amp;\in \text{SO}(3)\
\end{alignedat}$$
Functions $$\begin{alignedat}{3} \text{(skew) } \wedge &amp;amp;:&amp;amp; \mathbb{R}^3 &amp;amp;&amp;amp;\rightarrow \mathfrak{so}(3) &amp;amp;\
\exp &amp;amp;:&amp;amp; ~&amp;amp;&amp;amp;\mathfrak{so}(3) &amp;amp;\rightarrow \text{SO}(3)\
\text{Exp} &amp;amp;:&amp;amp; ~\mathbb{R}^3 &amp;amp;&amp;amp; &amp;amp;\rightarrow \text{SO}(3) \end{alignedat}$$
Thus, $$\begin{alignedat}{3} &amp;amp;\exp(\phi^\wedge) = \text{Exp}(\phi) = \mathbf{R} \end{alignedat}$$
Source: Forster 2017 IMU Preintegration At the identity Maps an element of the Lie algebra ($\phi^\wedge \in \mathfrak{so}(3)$, a skew symmetric matrix) to a rotation First order approximation $$ \exp(\phi^\wedge) \approx \mathbf{I} + \phi^\wedge$$</description></item><item><title>Lie group, Lie algebra</title><link>https://salehahr.github.io/zettelkasten/math/rotations/lie-group-lie-algebra/</link><pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/lie-group-lie-algebra/</guid><description>Lie group Parent: Rotations / SO(3) group index Source: http://www.seas.upenn.edu/~meam620/slides/kinematicsI.pdf
A group that is a differentiable (smooth) manifold is called a Lie group.
Lie algebra Source: http://en.wikipedia.org/wiki/3D_rotation_group Lie algebra $\mathfrak{so}(3)$
Every Lie group has an associated Lie algebra Lie algebra: linear space with same dimension as the Lie group Consists of all skew-symmetric 3x3 matrices Elements of the Lie algebra $\mathfrak{so}(3)$ are elements of the tangent space of the manifold SO(3)/Lie group at the identity element .</description></item><item><title>Logarithm map</title><link>https://salehahr.github.io/zettelkasten/math/rotations/logarithm-map/</link><pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/logarithm-map/</guid><description>Parents: Quaternion index , rotations / so(3) group-index Backlinks: Linearisation of an orientation in SO(3) Source: Forster 2017 IMU Preintegration Maps a rotation matrix $R$ in SO(3) to a skew-symmetric matrix ( Lie algebra ) Perturbations, first order approximation S. Forster [2015] suppplementary material for the inverse Jacobian
Source: MKok 2017 Approximations for small perturbations</description></item><item><title>Distal and proximal ends</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/distal-and-proximal-ends/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/distal-and-proximal-ends/</guid><description>Source: Leiner distal: far from the surgeon
proximal: near the surgeon</description></item><item><title>Endoscope</title><link>https://salehahr.github.io/zettelkasten/permanent/30.1.2-endoscope/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/permanent/30.1.2-endoscope/</guid><description>Source: NHS The general term for the medical instrument used to perform endoscopy is, correspondingly, the endoscope. It is a device that makes use of optical technology to relay images from one end of the scope to another.
Functions not only for looking inside, but also have additional functionalities such as removing small tissue samples (biopsy) Insertion either through
natural body orifices (e.g. mouth, urethra) small incision in case a keyhole surgery is being performed Subtopics Types of endoscopes Components Specification</description></item><item><title>Endoscopy</title><link>https://salehahr.github.io/zettelkasten/permanent/30.1.1-endoscopy/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/permanent/30.1.1-endoscopy/</guid><description>Source: NHS Backlinks: Endoscopes Endoscopy is a procedure which enables inspection of organs inside the body. The prefix &amp;lsquo;endo&amp;rsquo; comes from the Greek language and means &amp;lsquo;within&amp;rsquo; or &amp;lsquo;inside&amp;rsquo;, cf. the prefix &amp;lsquo;exo&amp;rsquo;/&amp;lsquo;ecto&amp;rsquo; meaning &amp;lsquo;outside&amp;rsquo;. Endo- from Greek ἔνδον (within, inside), cf. exo-/ecto- from έκτός (outside) The instrument: endoscope</description></item><item><title>Trocar</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/trocar/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/trocar/</guid><description>Source: https://en.wikipedia.org/wiki/Trocar
Here: surgical trocar
Used in [laparoscopic surgery](laparoscopic surgery.md) A medical device which is used to make small incisions and allows insertion of other surgical instruments into the body cavity Source: [Leiner Digital Endoscope Design](Leiner Digital Endoscope Design.md) In an arthroscopic procedure (knee?):
trocar is inserted into the cannula both are pushed through the skin trocar is replaced by obturator (blunt rod) to open the area up.</description></item><item><title>Markov assumption</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/markov-assumption/</link><pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/markov-assumption/</guid><description>Source: [MKok 2017 Using inertial sensors for position and orientation estimation](mkok 2017 using inertial sensors-for-position-and-orientation-estimation.md) Backlinks: [Grisetti 2011 - Tutorial graph-based SLAM](grisetti 2011 - tutorial graph-based slam.md), probabilistic models-for-imu Models with state x which have the Markov property:
all information up till time t is contained in xt enables marginalisation of state xt at time t+1</description></item><item><title>Descriptors in feature detection/extraction</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/descriptors-in-feature-detection-extraction/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/descriptors-in-feature-detection-extraction/</guid><description>Source: http://medium.com/data-breach/introduction-to-feature-detection-and-matching-65e27179885d
Backlinks: Bag of words Descriptors A description of the local appearance around each feature point (keypoint) The descriptor encodes &amp;lsquo;interesting&amp;rsquo; information from the image into numbers and act as an identifier (&amp;lsquo;fingerprint&amp;rsquo;) to differentiate between features The description should ideally be invariant to changes (such as illumination, translation, scale, in-plane rotation) so that the feature can be found again, even if the image is transformed Typically: for each feature point, there is a descriptor vector Classes of descriptors: Local descriptor represents the point&amp;rsquo;s local neighbourhood Global descriptor describes the whole image generally not very robust—changes in parts of the image may cause the descriptor to fail Some algorithms for feature detection/descriptor generation SIFT (scale-invariant feature transform) SURF (speeded up robust feature) BRISK (binary robust invariant scalable keypoints) BRIEF (binary robust independent elementary features) ORB (oriented FAST and rotated BRIEF) Source: http://en.</description></item><item><title>Manifolds</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/manifolds/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/manifolds/</guid><description>Source: https://www.euclideanspace.com/maths/geometry/space/surfaces/manifold/index.htm
Like a surface in $n$-dimensions (hypersurface) An $n$-dim manifold looks like $\mathbb{R}^n$ locally (locally Euclidian) Circle: 1-dim manifold. If we zoom around a point on the circle, it looks like a line ($\mathbb{R}^1$) Sphere: 2-dim manifold. Zooming onto a point, it looks like a plane ($\mathbb{R}^2$) Source: https://www.seas.upenn.edu/~meam620/slides/kinematicsI.pdf
An $n$-dim manifold is a a set $M$ which is locally homeomorphic to $\mathbb{R}^n$</description></item><item><title>SE(3) Special Euclidian Group</title><link>https://salehahr.github.io/zettelkasten/math/rotations/se3-special-euclidian-group/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/se3-special-euclidian-group/</guid><description>Source: Forster 2017 &amp;ndash; IMU Preintegration Group of rigid motion in 3D.
Consists of
a rotation in SO(3) a translation in $\mathbb{R}^3$ $$\begin{aligned} \text{SE}(3) \dot{=} \left\lbrace \left(\mathbf{R}, \mathbf{p} \right) : \mathbf{R} \in \text{SO}(3), \mathbf{p} \in \mathbb{R}^3 \right\rbrace \end{aligned}$$
$$\begin{aligned} \mathbf{T}_1\mathbf{T}_2 &amp;amp;= \left( \mathbf{R}_1\mathbf{R}_2, \mathbf{R}_1\mathbf{p}_2 + \mathbf{p}_1 \right)\
\mathbf{T}_1^{-1} &amp;amp;= \left( \mathbf{R}_1^\text{T}, -\mathbf{R}_1^{\text{T}}\mathbf{p}_1 \right) \end{aligned}$$</description></item><item><title>SO(3) 3D rotation group</title><link>https://salehahr.github.io/zettelkasten/math/rotations/so3-3d-rotation-group/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/rotations/so3-3d-rotation-group/</guid><description>Parent: Rotations / SO(3) group index See also: Orientation parametrisations , Linearisation of an orientation , Solà 2017 quaternion kinematics for eskf Source: MKok 2017 All orthogonal matrices with dim 3x3 have the property
$$RR^\text{T} = R^\text{T}R = I_3$$ They are part of the orthogonal group O(3) If, additionally, $\det R = 1$, then the matrix belongs to SO(3) and is a rotation matrix Source: http://en.wikipedia.org/wiki/3D_rotation_group The SO(3) group</description></item><item><title>Spaces in mathematics</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/spaces-in-mathematics/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/spaces-in-mathematics/</guid><description>Source: http://upload.wikimedia.org/wikiversity/en/c/cd/Spaces_in_mathematics.pdf Types of spaces in mathematics
Euclidian spaces (3D space, 2D space/Euclidian plane) Linear spaces Topological spaces Hilbert spaces etc. What is a space?
No real definition Made of selected mathematical objects which are treated as points selected relationships between these points Points can be elements of a set functions subspaces Isomorphic spaces are considered identical Isomorphism between two spaces: one-to-one mapping between the points, that preserves the relationships between the points</description></item><item><title>Parallax</title><link>https://salehahr.github.io/zettelkasten/definitions/parallax/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/parallax/</guid><description>Source: https://en.wikipedia.org/wiki/Parallax
See also: motion parallax Definition: The difference in the apparent position of an object viewed from two different positions
This difference is given by the angle between the two lines of sight Binocular vision uses parallax in the overlapping fields of vision in order to gain depth perception Distance measurement (i.e. depth from the viewer) via parallax is based on the principle of triangulation (uses trigonometry, s. Monocular depth perception in humans )</description></item><item><title>Covisible keyframes</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/covisible-keyframes/</link><pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/covisible-keyframes/</guid><description>Source: Palafox 2019 ( thesis ) Backlinks: Lamarca 2019 DefSLAM Two keyframes are covisible if they share several common landmarks.</description></item><item><title>Error ellipse/Confidence ellipse</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/error-ellipse-confidence-ellipse/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/error-ellipse-confidence-ellipse/</guid><description>Parent: Multivariate Gaussian distributions Source: rlabbe Kalman/Bayesian filters in Python Any slice through a multivariate Gaussian is an ellipse Plots show the slice for 3 standard deviations
Showing correlation using error ellipses</description></item><item><title>Central Limit Theorem</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/central-limit-theorem/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/central-limit-theorem/</guid><description>Parent: Gaussian distribution Source: rlabbe Kalman/Bayesian filters in Python If we make many measurements, the measurements will be normally distributed. (only applies under certain conditions)</description></item><item><title>Empirical rule 68/95/99.7</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/empirical-rule-68-95-99.7/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/empirical-rule-68-95-99.7/</guid><description>Source: rlabbe Kalman/Bayesian filters in Python Emprical rule, a.k.a. 68–95–99.7 rule About 68% of all values lie within one standard deviation of the mean.</description></item><item><title>Frequentist vs Bayesian statistics</title><link>https://salehahr.github.io/zettelkasten/math/statistics/frequentist-vs-bayesian/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/math/statistics/frequentist-vs-bayesian/</guid><description>Frequentist vs Bayesian statistics Sources: rlabbe , blitzstein-hwang Frequentist Probability represents the frequency over an experiment repeated infinitely many times Probability of flipping a fair coin infinitely many times is 50% Bayesian Probability represents a belief about the event [ bh ] $\hat{=}$ hypothesis e.g. probability that someone is guilty Probability of flipping a fair coin one more time: which way do I believe it landed?</description></item><item><title>Gaussian distribution</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/gaussian-distribution/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/gaussian-distribution/</guid><description>Parent: Probability theory Backlinks: Limitations of the discrete Bayes filter Source: rlabbe a.k.a. Normal distribution Unimodal, continuous probability distribution function (pdf)
The probability of a range of measurements is the area under the graph of the probability distribution between the end values of the range &amp;ndash; cumulative distribution function (cdf)
Background statistics Variance, standard deviation, covariances Central Limit Theorem Correlation and independence Types Univariate Gaussian distribution Multivariate Gaussian distributions Computational properties of Gaussian distributions Pros and cons of Gaussian distributions</description></item><item><title>Multivariate Gaussian distributions</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-gaussian-distributions/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/multivariate-gaussian-distributions/</guid><description>Parent: Gaussian distribution Source: rlabbe Kalman/Bayesian filters in Python See also: Probability distribution N means for N dimensions Variances are now also combined with covariances (to take into account correlation between different dimensions)
Variance: how does a population vary amongst themselves? Covariance: how much do two variables change relative to each other? The correlation helps prediction!
Here: only linear correlation considered; however nonlinear correlations also exist.
Error ellipse/Confidence ellipse</description></item><item><title>Probability distribution</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/probability-distribution/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/probability-distribution/</guid><description>Parents: Discrete Bayesian filter , Probability theory Source: rlabbe Probability distribution collection of all possible probabilities for an event the distribution lists all possible events and the probability of each sum up to 1 Prior probability distribution probability prior to incorporating any measurements or other information
Joint probability $P(x,y)$: probability of both events happening the multivariate Gaussian distribution is already a joint probability distribution Marginal probability $P(x)$: probability of an event happening, without considering the occurrence of other events &amp;lsquo;projecting&amp;rsquo; the variances onto the walls</description></item><item><title>Random variable</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/random-variable/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/random-variable/</guid><description>Random variable $X$ Source: Wiki Alternative name: stochastic variable Function that assigns each elementary outcome $\omega$ in the sample set $\Omega$ to another set $\mathcal{A}$ (often to $\mathbb{R}$) $$X: \Omega \rightarrow \mathcal{A}$$ $P(X = x)$ is the probability that the function $X$ attains the value $x \in \mathcal{A}$ $x$: specific realisation of a random variable $X$ Can be discrete (e.g. number of students) or continuous (e.g. height of students) Example Source Experiment: two dice are thrown Sample set: $\left{ (D_i, D_j) \right}$ $\forall, i,j$ $X$: random variable that gives the number of dice with sixes Example trials: Trial 1: (2, 3) &amp;ndash;&amp;gt; $X = 0$ Trial 2: (6, 1) &amp;ndash;&amp;gt; $X = 1$ Trial 3: (6, 6) &amp;ndash;&amp;gt; $X = 2$</description></item><item><title>Smug filter</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/smug-filter/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/smug-filter/</guid><description>Parent: 1D Kalman filter algorithm Source: rlabbe Kalman/Bayesian filters in Python A filter that, once enough measurements are made, becomes very confident in its prediction (P gets smaller with time while the filter becomes more inaccurate!). From then on it will ignore measurements
To avoid this: add a bit of error to the prediction step, e.g. using the process variance</description></item><item><title>Variance, standard deviation, covariances</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/variance-standard-deviation-covariances/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/variance-standard-deviation-covariances/</guid><description>Backlinks: Multivariate Gaussian distributions Source: rlabbe Kalman/Bayesian filters in Python See also: Empirical rule 68/95/99.7 How much do the values vary from the mean?
There are other ways of calculating variance (e.g. by using absolute values of error instead of error squared). The other methods may be better w.r.t. outliers (outliers get magnified in the square term) Process variance: error in the process model Sensor variance: error in each sensor measurement</description></item><item><title>Conditional independence</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/conditional-independence/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/conditional-independence/</guid><description>Parent: Probability theory Source: http://en.wikipedia.org/wiki/Conditional_independence $A$ and $B$ are conditionally independent given $C$ $\Leftrightarrow$ given the knowledge that $C$ occurs, the knowledge of whether $A$ occurs provides no information whatsoever on the likelihood of $B$ occurring, and vice versa.
Examples Weather and delay Let the two events be the probabilities of persons $A$ and $B$ getting home in time for dinner The third event $C$ is the fact that a snow storm hit the city.</description></item><item><title>Egomotion (vs odometry)</title><link>https://salehahr.github.io/zettelkasten/definitions/egomotion-vs-odometry/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/egomotion-vs-odometry/</guid><description>See also: Odometry Source: http://en.wiktionary.org/wiki/egomotion
The three-dimensional movement of a camera relative to its environment
Source: http://answers.ros.org/question/296686/what-is-the-differences-between-ego-motion-and-odometry/
Generally used interchangeably with odometry Possible difference: Egomotion is more about the estimation of twist (lin, rotational velocities) Odometry is more about the estimation of path Examples Wheel odometry: path estimation via time-integration of an estimated twist Visual odometry/Scan matching: direct estimation of pose without time-integration</description></item><item><title>Perceptual aliasing</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/perceptual-aliasing/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/perceptual-aliasing/</guid><description>Source: http://en.wikipedia.org/wiki/Robotic_mapping Two different places are perceived as the same
Source: http://arxiv.org/abs/1810.11692 Modeling Perceptual Aliasing in SLAM via Discrete-Continuous Graphical Models [Lajoie 2018] (from the abstract)
Phenomenon where different places generate a similar visual footprint Leads to spurious measurements being fed into the SLAM estimator Result: incorrect localisation and map</description></item><item><title>In vivo</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/in-vivo/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/in-vivo/</guid><description> Latin for &amp;ldquo;within the living&amp;rdquo; studies in which the effects of various biological entities are tested on whole, living organisms or cells, as opposed to a tissue extract/dead organism</description></item><item><title>Odometry</title><link>https://salehahr.github.io/zettelkasten/definitions/odometry/</link><pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/odometry/</guid><description>See also: Egomotion (vs odometry) Source: https://en.wikipedia.org/wiki/Dead_reckoning In navigation, dead reckoning is the process of calculating one&amp;rsquo;s current position by using a previously determined position, by using estimations of speed and course over elapsed time
s. Brian Douglas video on sensor fusion Source: Wikipedia Visual odometry Data can be generated from actuator movements, e.g. rotary encoders that measure motor shaft rotations This data can be used to estimate changes in position over time Usually has precision problems, e.</description></item><item><title>Cryosection</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cryosection/</link><pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cryosection/</guid><description>Source: https://en.wikipedia.org/wiki/Frozen_section_procedure aka frozen section procedure allows rapid analysis of a dissected/resected specimen during the course of surgery the specimen is frozen rapidly and brought to a lab for analysis the results are relayed to the surgeon by intercom benign or malignant when operating on a previously confirmed malignant tissue, information on whether residual cancer was found on the [resection margin](resection margin.md) of the tissue the surgeon makes his decision on how to continue the operation based on the results</description></item><item><title>Oncology</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/oncology/</link><pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/oncology/</guid><description>Source: https://en.wikipedia.org/wiki/Oncology Backlinks: [GRK 2543: Intraoperative Multi-sensor Tissue Differentiation in Oncology](GRK 2543_ Intraoperative Multi-sensor Tissue Differentiation in Oncology.md)
Prevention, diagnosis and treatment of cancer.</description></item><item><title>Related types of surgery</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/related-types-of-surgery/</link><pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/related-types-of-surgery/</guid><description>Source: http://en.wikipedia.org/wiki/Resection_(surgery) By procedure Resection: remove all parts or a key part of an internal organ s. also: resection margin Excision: cut out only a part of an organ/tissue By degree of invasiveness minimally-invasive surgery (-scopy) laparoscopy</description></item><item><title>Resection margin</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/resection-margin/</link><pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/resection-margin/</guid><description>Source: http://en.wikipedia.org/wiki/Resection_margin Backlinks: Cryosection , related types-of-surgery Margin on non-cancerous tissue around a tumour that has been removed.
Negative margin: no tumour Microscopic positive: tumour identified microscopically Macroscopic positive: tumour significantly present</description></item><item><title>Simplex</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/simplex/</link><pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/simplex/</guid><description>Source: https://en.wikipedia.org/wiki/Simplex Parent: [Barycentric coordinates](Barycentric coordinates.md)
A triangle in arbitrary dimensions 0-simplex point 1-simplex line 2-simplex triangle 3-simplex tetrahedron</description></item><item><title>Cancer biopsy</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cancer-biopsy/</link><pubDate>Sat, 08 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cancer-biopsy/</guid><description>Source: http://en.wikipedia.org/wiki/Biopsy
Biopsy type of medical test in which a cell/tissue sample is extracted in order to detect disease
Types of biopsy: excisional biopsy: removal of entire suspicious area to be diagnosed incisional biopsy: removal of only samples of the abnormal tissue needle aspiration biopsy: removal of cells via needle Diagnosing / Pathological examination to determine whether the abnormality is benign or malignant (classification of the cancer) to determine how far it has spread negative margins: no disease found at the edge of specimen positive margins: disease was found at edge, further excision may be in order In bladders: usually done using a cystocopy</description></item><item><title>Cystocopy</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/cystocopy/</link><pubDate>Sat, 08 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/cystocopy/</guid><description>Source: https://en.wikipedia.org/wiki/Cystoscopy
Backlinks: [Some questions](Some questions.md)
Endoscopy of the bladder via the urethra Tool involved: cystoscope https://www.youtube.com/watch?v=ybhzlW7ivro
Video of cystocopy and bladder biopsy Modern Latin for bladder: cystis</description></item><item><title>Laparoscopy</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/laparoscopy/</link><pubDate>Sat, 08 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/laparoscopy/</guid><description>Source: https://en.wikipedia.org/wiki/Laparoscopy Backlinks: [Related types of surgery](Related types of surgery.md), [Some questions](Some questions.md), Trocar minimally invasive surgery (MIS) / keyhole surgery make a small incision in the abdomen area and operate through it</description></item><item><title>Registration</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/registration/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/registration/</guid><description> Aligning two points, each in different spaces respectively, together Examples aligning an endoscope coordinate frame to CT data (based on a similarity metric between endoscopic image and CT image) &amp;ndash; from https://pubmed.ncbi.nlm.nih.gov/25991876/ match virtual surface to corresponding endoscopic video &amp;ndash; https://ieeexplore.ieee.org/document/958638 Parent: SofaPython Index allows a matching between deformable surfaces finds spatial transformations to align two point sets or two meshes done based on: either target surfaces (ClosestPointRegistrationForceField , RegistrationContactForceField) or target images (IntensityProfileRegistrationForceField), which requires the use of the image plugin</description></item><item><title>Motion parallax</title><link>https://salehahr.github.io/zettelkasten/definitions/motion-parallax/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/definitions/motion-parallax/</guid><description>Motion parallax closer objects visually shift much more than distant ones when we move</description></item></channel></rss>