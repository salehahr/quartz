<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SLAM/algos/DefSLAM on Zettelkasten</title><link>https://salehahr.github.io/zettelkasten/tags/SLAM/algos/DefSLAM/</link><description>Recent content in SLAM/algos/DefSLAM on Zettelkasten</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/SLAM/algos/DefSLAM/index.xml" rel="self" type="application/rss+xml"/><item><title>System::forceTrajectory</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/system-forcetrajectory/</link><pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/system-forcetrajectory/</guid><description>Parent: DefSLAM branch overview Reference: DefSLAMGT (stereo as ground truth) For testing: DefSLAMVI
Description Force update of DefSLAMVI&amp;rsquo;s current frame pose to that of DefSLAMGT&amp;rsquo;s for the frames 230 to 239
Without System::Reset Frame pose is &amp;lsquo;updated&amp;rsquo; during the interval, but after the interval, the optimisation (which uses frame pose as an estimate and also uses map node positions) makes the system resume it&amp;rsquo;s trajectory before the update
(below: with pure monocular trajectory, without any forced updates) With System::Reset The system is reset after every forced pose update (i.</description></item><item><title>DefSLAM branch overview</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-branch-overview/</link><pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-branch-overview/</guid><description>Parent: SA TODO Repo http://github.com/feudalism/DefSLAM
Dormant
master sa Deprecated
windows - deprecated, changes made for building on Windows imu - deprecated, has Imu tracking functions but dependencies not resolved obs_tuple - initial attempt to incorporate Atlas, attempt to use OS3&amp;rsquo;s structure for MapPoint observations : &amp;lt;KeyFrame, tuple&amp;lt;int, int&amp;raquo; as opposed to &amp;lt;Keyframe, int&amp;gt; in DefSLAM+OS2 Temporary/Experimental
s. to do list
debugging the segfault that seemingly appears in Surface::getNormalSurfacePoint seems to happen after System reset</description></item><item><title>ORBSLAM2 unofficial documentation</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam2-unofficial-documentation/</link><pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam2-unofficial-documentation/</guid><description>Partially done, abandonned: http://github.com/raulmur/ORB_SLAM2/compare/master&amp;hellip;AlejandroSilvestri:master In Spanish: http://alejandrosilvestri.github.io/os1/doc/html/</description></item><item><title>NormalSurfacePoint Segfault</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/normalsurfacepoint-segfault/</link><pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/normalsurfacepoint-segfault/</guid><description>Crash around frame 65 [New Thread 0x7fff7ffff700 (LWP 3854)] [Thread 0x7fff7ffff700 (LWP 3854) exited] [New Thread 0x7fff7ffff700 (LWP 3855)] [Thread 0x7fff7ffff700 (LWP 3855) exited] [New Thread 0x7fff7ffff700 (LWP 3856)]
Thread 5 &amp;ldquo;DefSLAM&amp;rdquo; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7fffc215d700 (LWP 3571)] defSLAM::SurfacePoint::thereisNormal (this=0x6705) at /home/user3/slam/DefSLAM/Modules/Mapping/SurfacePoint.cc:54 54 bool SurfacePoint::thereisNormal() { return NormalOn; } (gdb) bt #0 0x00007ffff78798a0 in defSLAM::SurfacePoint::thereisNormal() (this=0x6705) at /home/user3/slam/DefSLAM/Modules/Mapping/SurfacePoint.cc:54 #1 0x00007ffff7878f95 in defSLAM::Surface::setNormalSurfacePoint(unsigned long, cv::Vec&amp;lt;float, 3&amp;gt;&amp;amp;) (this=0x555565b0e030, ind=ind@entry=939, N=&amp;hellip;) at /home/user3/slam/DefSLAM/Modules/Mapping/Surface.</description></item><item><title>Viewer segfault</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/viewer-segfault/</link><pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/viewer-segfault/</guid><description>Error [New Thread 0x7fff86ffd700 (LWP 1117)] NORMALS REESTIMATED : 277 - 277 [Thread 0x7fff86ffd700 (LWP 1117) exited] NORMAL ESTIMATOR OUTPoints potential : 293 70 New template requested Number Of normals 277 0x555566923da0 -0.79956 0.655022 -0.594482POINTS matched:167 Points Scale Error Keyframe : 1 stan dev 0.310974 chi 0.013115 0.01 201 SurfaceRegistration not sucessful (Not enough points to align or chi2 too big
Thread 6 &amp;ldquo;DefSLAM&amp;rdquo; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7fffc1996700 (LWP 275)] __memmove_avx_unaligned_erms () at .</description></item><item><title>Segfault in DefTracking (imu branch)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/segfault-in-deftracking-imu-branch/</link><pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/segfault-in-deftracking-imu-branch/</guid><description>/home/user3/slam/datasets/mandala0/images/stereo_im_l_1560936003993.png i: 30 POINTS matched:10 Track lost soon after initialisation, reseting&amp;hellip; /home/user3/slam/datasets/mandala0/images/stereo_im_l_1560936004022.png i: 31 System Reseting NORMAL ESTIMATOR IN - NORMALS REESTIMATED : 0 - 0 NORMAL ESTIMATOR OUTPoints potential : 939 70 New template requested Number Of normals 0 0x5555636b1fb0 Not enough normals Reseting Local Mapper&amp;hellip; done Reseting Loop Closing&amp;hellip; done Reseting Database&amp;hellip; done
Thread 1 &amp;ldquo;DefSLAM&amp;rdquo; received signal SIGSEGV, Segmentation fault. 0x00007ffff78d9fae in cv::Mat::Mat (m=&amp;hellip;, this=0x7ffffffeaea0) at /usr/local/include/opencv4/opencv2/core/mat.inl.hpp:545 545 step[0] = m.</description></item><item><title>DefSLAM and discontinuous areas (classical datasets)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-and-discontinuous-areas-classical-datasets/</link><pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-and-discontinuous-areas-classical-datasets/</guid><description>Parent: Lamarca 2020 DefSLAM Source: http://github.com/UZ-SLAMLab/DefSLAM/issues/1
JoseLamarca: DefSLAM is suitable for rigid areas, proof of that is the abdominal sequence that is kind of rigid. The problem for these sequences is the discontinuous areas. For the monocular case, we are assuming that the surface is smooth that is not usually valid for the classical datasets. Apart from complexity issues that algorithms with RGB-D and stereo cameras could have in those scenes [1] and [2].</description></item><item><title>DefSLAM errors encountered</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-errors-encountered/</link><pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-errors-encountered/</guid><description>Rebuilding DefSLAM in Debug mode Error: &amp;ldquo;Virtual memory exhausted: Cannot allocate memory&amp;rdquo; Solution: reduce degree of make -j
Segmentation fault in Defslam debug mode Based on http://stackoverflow.com/questions/19615371/segmentation-fault-due-to-vectors Changed: surfacePoints_[ind] to surfacePoints_.at(ind)
New error surfacePoints_ appears to be NULL? Was it instantiated in another thread? http://stackoverflow.com/questions/11645857/debugging-with-gdb-why-this-0x0
Using core dumps with gdb http://jvns.ca/blog/2018/04/28/debugging-a-segfault-on-linux/</description></item><item><title>Pizarro 2016 Schwarps</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</link><pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/pizarro-2016-schwarps/</guid><description>Author: Daniel Pizarro et al.
Abstract
Warp between two images of a deforming surface: a transformation that depict the geometric deformation between the two &amp;lsquo;maps points between images of a deforming surface&amp;rsquo; Current approach to enforce a warp&amp;rsquo;s smoothness: penalise its second order partial derivatives However this favours locally affine warps Does not capture the local projective component of the image deformation Propose: novel penalty to smooth the warp while capturing the deformation&amp;rsquo;s local projective structure Proposed penalty is based on equivalents to the Schwarzian derivatives Schwarzian derivatives: projective differential invariants exactly preserved by homographies Methodology to derive a set of PDEs with only homographies as the solutions Validation: Schwarps outperform existing warps in modeling and extrapolation power: perform better in deformable reconstruction methods Introduction/Related work</description></item><item><title>Non-Rigid Guided Matching (b/w KFs) in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/non-rigid-guided-matching-b-w-kfs-in-defslam/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/non-rigid-guided-matching-b-w-kfs-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Backlinks: NRSfM in DefSLAM Matching between keyframes (used in deformation mapping in DefSLAM)
Use an estimated warp as a reference
To increase number of matches in the covisible keyframes Process
Matches are given by deformation tracking Estimate an initial warp between k and k* (covisible keyframes) how? Using this initial warp, estimate where a point would be seen in k* Define a search region around thesse estimated positions.</description></item><item><title>Surface alignment in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/surface-alignment-in-defslam/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/surface-alignment-in-defslam/</guid><description>Parent: Mapping step-by-step in DefSLAM Source: Lamarca 2019 DefSLAM Goal:
to scale the up-to-scale surface (output of NRSfM) to the proper dimensions get an idea of the proper dimensions from the already estimated map i.e. resulting surface must match the scale of the template T_(k-1) T_(k-1): deformed map generated by the tracker at the instance of KF=k insertion, with shape-at-rest of S_(k-1) generated from KF:(k-1) result: scale-corrected shape-at-rest Sk Method:</description></item><item><title>Template substitution in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/template-substitution-in-defslam/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/template-substitution-in-defslam/</guid><description>Parent: Mapping step-by-step in DefSLAM Source: Lamarca 2019 DefSLAM Tracking runs at frame-rate, and mapping at keyframe-rate Tracking processes Nm frames during a whole mapping run Process
New keyframe (k) is made. Now at time t=k At this point, the template in the tracking is still based on the old shape-at-rest, S_(k-1) Mapping thread starts creates surface S_k which is aligned to prev. template T_(k-1) k is set as the reference keyframe from S_k, create template T_k and from now on use this template instead of the old one T_(k-1) At time t=k+Nm, use data from the tracking thread image points at t=k+Nm deform the recently computed template T_k based on these images use SfT but neglecting the temporal term (to allow large deformation, &amp;ldquo;as a lot might have happened in the time span of Nm&amp;rdquo;) so now we get a T_k that is deformed (updated) to the most recent image points we do this extra step instead of passing T_k (from step 1) to the tracker immediately because, due to the new points occurring at t=k+Nm, using the original T_k might lead to data association errors mapper passes the new template T_k (t=k+Nm) to the tracker</description></item><item><title>Data association in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/data-association-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/data-association-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM See also: Data association Goal: match keypoints in current frame (newly extracted) with map points (already in map/system) Use the active matching strategy proposed in [Agudo 2015]: “Simultaneous pose and non-rigid shape with particle dynamics,” Steps  ORB points (keypoints) are detected in current frame
Camera pose Tcw is predicted
using camera motion model camera motion model: function of past camera poses Predict where map points (existing in map) would be imaged, based on last estimated template i.</description></item><item><title>DefSLAM framework</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-framework/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-framework/</guid><description>Source: Lamarca 2019 DefSLAM &amp;ldquo;Fusion of the methods available for processing non-rigid monocular scenes&amp;rdquo;
Deformation tracking [front end]
estimates/recovers/optimises: camera pose scene deformation / deformation of map points (observations) the map points are then embedded into the template Tk (to compute their position on the surface) operates at frame rate SFT-based (shape from template), requires prior geometry (template of scene at rest) for the currently being viewed map Map points are deformed (updated) by solving an optimisation problem min { reprojection error + deformation energy } per frame Deformation mapping [back end]</description></item><item><title>Mapping step-by-step in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mapping-step-by-step-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mapping-step-by-step-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Parent: DefSLAM framework Steps
Recover warps between k and k* (s. [Non-Rigid Guided Matching (b/w KFs) in DefSLAM](non-rigid guided-matching-(b_w-kfs)-in-defslam.md)) with k: anchor keyframes, i.e. KFs where one of the observed map points was initialised with k*: set of best covisible keyframes warps: transformation between the images Ik to Ik* In DefSLAM, Schwarps (a family of warps using 2D Schwarzian equation regularisers) is used Schwarps has something to do with the infinitesimal planarity assumption of NRSfM [ NRSfM ] Process k* to get estimate of an up-to-scale surface  Input of NRSfM: warps [ Surface alignment ] Up-to-scale surface (\hat{S}_k) is aligned with the whole map in order to obtained the scaled surface Sk w.</description></item><item><title>NRSfM and SfT</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm-and-sft/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm-and-sft/</guid><description>Source: Lamarca 2019 DefSLAM In literature, non-rigid monocular scenes are handled by NRSfM and SfT
NRSfM (non-rigid structure from motion)
batch processing of images to recover deformation computationally demanding — slower than SFT SFT (shape from template)
uses only a single image — faster than NRFfM lower computational cost must have a known 3D template (textured model)</description></item><item><title>NRSfM in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/nrsfm-in-defslam/</guid><description>Parent: Mapping step-by-step in DefSLAM Source: Lamarca 2019 DefSLAM Assumptions
Isometric deformation Infinitesimal planarity [DEF]: any surface can be approximated as a plane at infinitesimal level, all the while maintaining its curvature at a global level The method used here is a local method &amp;ndash;&amp;gt; implies that it handles missing data and occlusions inherently
surface deformation is modelled locally for each point, under the above assumptions Embedding, phi_k of the scene surface</description></item><item><title>Template in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/template-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/template-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Template
2D triangular mesh floating in the 3D space consists of a set of 2D triangular facets F a facet has 3 nodes (set V) and 3 edges (set E) map points observed in keyframe k are embedded in the facets Map point coordinates in barycentric coordinates</description></item><item><title>Tracking optimisation in DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-optimisation-in-defslam/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-optimisation-in-defslam/</guid><description>Source: Lamarca 2019 DefSLAM Backlinks: Template substitution in DefSLAM Optimisation function
Minimises reprojection error (in the image) deformation energy (of the template) boundary nodes of the local zone are fixed (i.e. not set as arguments to the optimisation function) this makes the absolute camera pose observable how? in order to constrain the gauge freedoms Initial guess: values from previous optimisation (i.e. previous frame: t-1) Reprojection error robust against outliers due to Huber robust kernel</description></item><item><title>DefSLAM dependency/inheritance diagram</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-dependency-inheritance-diagram/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-dependency-inheritance-diagram/</guid><description/></item><item><title>DefTracking::MonocularInitialization</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-monocularinitialization/</link><pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-monocularinitialization/</guid><description>Parent: DefTracking::Track Initialises
surface points in the surface If num. features in current frame &amp;gt; 100
set frame pose to origin make new KF (GroundTruthKeyFrame) pKFini add the KF to the map mpMap iterate over the N features get feature kp convert kp to 3d point make new DefMapPoint(3dp, pKFini, mpMap) set pointers between DefMapPoint, GroundTruthKeyFrame, DefMap Save surface using bbs Set mLastFrame := mCurrentFrame Local window: Add KF to local KFs vector, add MapPoints to local MP vector, mpLocalMapper Calculate Tcr from Tcw Initialise SLAM: Set reference KF, reference MapPoints set mState to OK</description></item><item><title>ORBSLAM::Frame constructor (monocular)</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam-frame-constructor-monocular/</link><pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/orbslam-frame-constructor-monocular/</guid><description>Source: Tracking::GrabImageMonocular Set scale level info from ORB extractor Extract ORB features mvKeys (vector of keypoints/features) Set N number of features Make mvpMapPoints (null, but with size N), mvbOutlier (all entries false, size N) If first frame or calibration change: ComputeImageBounds AssignFeaturesToGrid()</description></item><item><title>DefOptimizer::DefPoseOptimization</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defoptimizer-defposeoptimization/</link><pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defoptimizer-defposeoptimization/</guid><description>Parent: DefTracking::Track As far as I understand it:
Uses g2o library for the optimisation (graph-based SLAM) cost function terms are converted to edges and nodes each cost function term seems to correspond to an edge in the graph in g2o paper/tutorial: an edge is fully characterised by its error function and its information matrix int DefPoseOptimization(Frame *pFrame, Map *mMap, double RegLap, double RegInex, double RegTemp, uint NeighboursLayers) // define optimiser, set solver optimizer = new &amp;hellip; optimizer.</description></item><item><title>DefOptimizer::poseOptimization</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defoptimizer-poseoptimization/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defoptimizer-poseoptimization/</guid><description>Parent: DefTracking:TrackWithMotionModel() int DefOptimizer::poseOptimization(Frame *pFrame)
// Set estimate of solution to current camera pose g2o::VertexSE3Expmap *vSE3 = new g2o::VertexSE3Expmap(); vSE3-&amp;gt;setEstimate(Converter::toSE3Quat(pFrame-&amp;gt;mTcw)); vSE3-&amp;gt;setId(0); vSE3-&amp;gt;setFixed(false); optimizer.addVertex(vSE3);
// Set MapPoint vertices (num. nodes in opt. graph?) const int N = pFrame-&amp;gt;N;</description></item><item><title>defSLAM::System constructor</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-system-constructor/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-system-constructor/</guid><description>Parent: DefSLAM simple_camera defSLAM::System::System(const string &amp;amp;strVocFile, const string &amp;amp;strSettingsFile, const bool bUseViewer)  mSensor(MONOCULAR), mpLoopCloser(NULL), mpViewer(static_cast&amp;lt;Viewer *&amp;gt;(nullptr)), mbReset(false), mbActivateLocalizationMode(false), mbDeactivateLocalizationMode(false) Constructor // initialise mpVocabulary from file // create mpKeyFrameDatabase from mpVocabulary // create map DefMap() // create drawers for viewer DefFrameDrawer DefMapDrawer // initialise tracking, mapping, viewer threads; loop closing not implemented in DefSLAM mpTracker = new DefTracking(&amp;hellip;); mpLocalMapper = new DefLocalMapping(&amp;hellip;); mpViewer = new DefViewer(&amp;hellip;);
Attributes eSensor mSensor ORBVocabulary *mpVocabulary KeyFrameDatabase *mpKeyFrameDatabase Map *mpMap // stores pointers to all KFs, all MapPoints</description></item><item><title>defSLAM::System::TrackMonocular</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-system-trackmonocular/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-system-trackmonocular/</guid><description>Parent: DefSLAM simple_camera cv::Mat defSLAM::System::TrackMonocular cv::Mat Tcw = mpTracker-&amp;gt; GrabImageMonocular (im, timestamp);
// get information from mpTracker: // get states mTrackingState // get map points mTrackedMapPoints // get key points mTrackedKeyPointsUn
// return camera pose return Tcw;</description></item><item><title>DefTracking::Track</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-track/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-track/</guid><description>Parent: Tracking::GrabImageMonocular void DefTracking::Track // if: not initialised, do: monocular initialisation // elseif: already initialised, do: track frame { // if: tracking and mapping, do: bOK = TrackWithMotionModel ();
// if bOK (there exists camera pose estimate and matching), track local map // if template is updated (keyframe-rate update) set reference KF from new template do DefPoseOptimization (&amp;hellip;); bOK = TrackLocalMap();
// if: bOK, update motion model (update mVelocity); clean VO matches // check if we should insert a new KF, delete outliers for BA</description></item><item><title>DefTracking:TrackWithMotionModel()</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-trackwithmotionmodel-/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/deftracking-trackwithmotionmodel-/</guid><description>Parent: DefTracking::Track // Initial tracking to locate rigidly the camera and discard outliers. bool DefTracking::TrackWithMotionModel()
// Update last frame relative pose according to its reference keyframe UpdateLastFrame();
// Project points seen in prev frames int th = 15; int nmatches = Defmatcher.SearchByProjection(*mCurrentFrame, mLastFrame, th, mSensor == System::MONOCULAR);
// Optimise frame pose with all matches to initialise camera pose Optimizer:: poseOptimization (mCurrentFrame, myfile);
// Discard outliers
// return: sufficient number of matches?</description></item><item><title>Tracking_GrabImageMonocular</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-grabimagemonocular/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-grabimagemonocular/</guid><description>Parent: defSLAM::System::TrackMonocular cv::Mat ORB_SLAM2::Tracking::GrabImageMonocular
colour conversion make frame using image, timestamp, ORB stuff, calibration data, etc. mCurrentFrame = new Frame (mImGray, timestamp, mpORBextractorLeft, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth, im)
perform tracking: Track (); return camera pose return mCurrentFrame-&amp;gt;mTcw.clone();</description></item><item><title>DefSLAM simple_camera</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-simple-camera/</link><pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/defslam-simple-camera/</guid><description>Without ground truth
App run // Create defSLAM::system, which initializes all threads (local mapping, loop closing, viewer) defSLAM::System SLAM(orbVocab, calibFile, bUseViewer);
// Timestamp uint timestamp := 0;
// Process frames from video capture while (capture.isOpened()) { // Get the capture as a matrix; // SLAM SLAM. TrackMonocular (img_matrix, timestamp); timestamp++; }</description></item><item><title>Lamarca 2020 DefSLAM</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/lamarca-2020/</guid><description>URL: http://arxiv.org/abs/1908.08918 Authors: Lamarca et al Code: http://github.com/UZ-SLAMLab/DefSLAM Results (video): http://www.youtube.com/watch?v=6mmhD2_t6Gs Summary
First monocular SLAM for deformable environments in real-time Most other SLAM implementations assume rigidity Main techniques used (techniques for monocular non-rigid scenes): isometric shape from template (SfT) non-rigid structure from motion (NRSfM) Main principle: computation in two parallel threads (s. DefSLAM framework) Deformation tracking [front end] Deformation mapping [back end] The map from the mapping thread defines the shape-at-rest template used by deformation tracking Validation: compare with ORBSLAM (rigid) Assumes isometric deformation Future work: relocalisation (s.</description></item></channel></rss>