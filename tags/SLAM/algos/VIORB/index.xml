<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SLAM/algos/VIORB on</title><link>https://salehahr.github.io/zettelkasten/tags/SLAM/algos/VIORB/</link><description>Recent content in SLAM/algos/VIORB on</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://salehahr.github.io/zettelkasten/tags/SLAM/algos/VIORB/index.xml" rel="self" type="application/rss+xml"/><item><title>(Mur-Artal 2017) VI-ORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mur-artal-2017-vi-orb/</guid><description>Backlinks: Chen 2018 Review of VI SLAM , [keyframe-based tightly-coupled multisensor slam](keyframe-based tightly-coupled multisensor slam.md), todo , works of-possible-interest URL: http://ieeexplore.ieee.org/abstract/document/7817784, Authors: Mur-Artal, Tardós Code: http://paperswithcode.com/paper/visual-inertial-monocular-slam-with-map-reuse Results (video): http://www.youtube.com/watch?v=JXRCSovuxbA
Abstract
current VI odometry approaches: drift accumulates due to lack of loop closure therefore there is a need for tightly-coupled VI-SLAM with loop closure and map reuse here: focus on monocular case, but applicable to other camera configurations builds on ORB-SLAM (from same author) IMU initialisation method (initialises: scale, gravity direction, velocities, gyroscope bias, accelerometer bias) depends on visual monocular initialisation (coupled initialisation) Other works: recent tightly-coupled VIO (both filtering- and optimisation-based) lack loop closure, so drift accumulates</description></item><item><title>Loop closing in VIORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/loop-closing-in-viorb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/loop-closing-in-viorb/</guid><description>Parent: SLAM Index Source: Mur-Artal 2017 VI-ORB Overview
To reduce drift accumulated during exploration (when returning to an already mapped location) Loop detection: of large loops using place recognition Loop correction: first do lightweight pose-graph optimisation (PGO), then do full BA in a separate thread (in order not to interfere with real-time operations) Implementation
After loop detection: do match validation (alignment of points between keyframes) Then pose-graph optimisation to reduce the accumulated error in trajectory (PGO: pose-only, ignores IMU info) IMU info ignored, but velocities are corrected by rotating them according to keyframe orientation &amp;ndash;&amp;gt; suboptimal, but should be accurate enough to allow IMU data to be used right after the PGO in ORBSLAM: PGO is 7-DoF optimisation (due to scale + 3 rot + 3 xyz) in VIORB, 6 DoF (scale is known from initialisation bzw.</description></item><item><title>Mapping in VIORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/mapping-in-viorb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/mapping-in-viorb/</guid><description>Source: Mur-Artal 2017 VI-ORB Mapping in VIORB Previously in ORBSLAM (only poses are optimised): Now in VIORB, more states to optimise: Increase in complexity
more states to optimise (v, b) IMU measurements creates constraints between keyframes Original ORBSLAM discards redundants KFs (poses a problem with IMU constraints!) Workaround: in local BA, only allow discarding of KF if, after discarding, the time between two consecutive KFs is short enough (&amp;lt;= 0.</description></item><item><title>Tracking in VIORB</title><link>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://salehahr.github.io/zettelkasten/studienarbeit/tracking-in-viorb/</guid><description>Source: Mur-Artal 2017 VI-ORB Tracking in VIORB
Visual-inertial tracking at frame rate, instead of using an ad-hoc motion model as in the original ORB-SLAM Tracked states: [sensor pose (R, p), velocities v, biases b] Once the camera pose is predicted, map points are projected, then matches with existing features on the frame Then optimise the current frame j, depending on whether the map has just been updated the map is unchanged Here, the optimisation function for tracking (when map unchanged) is:</description></item></channel></rss>