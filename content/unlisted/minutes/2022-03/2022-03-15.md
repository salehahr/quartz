---
title: 2022-03-15
date: 2022-03-13
tags:
  - ma
---

## Agenda
* Fallunterscheidung when updating the adjacencies
* Starting with a large number of neighbours (seems to be better); batch size = num of neighbours
* To do?: increase threshold for adjacency probabilities


## Outcomes
* Note: probability output of a neural network used for classfication, s.
    * https://stats.stackexchange.com/questions/256420/neural-networks-output-probability-estimates
    * https://arxiv.org/pdf/1706.04599.pdf
  > Softmax of state-of-art deep learning models is more of a score than probability estimates.
* High prio tasks
    * [ ] Thesis
    * [x] Adjust validation DG (ratio of edges to non-edges)
    * [x] resume training on 16.03
    * [x] Check degrees in loaded graphs of the problematic files ([fix](https://github.com/salehahr/tfgraph/commit/d52e0de12ff521064c8f21b0574d4b14e153c2d0))
    * [ ] Hyperparameter optimisation
    * [ ] Figure out how to reduce time taken for iterations in combinatorial prediction of $A$
* Lower prio
    * [ ] Brute force prediction of $A$, VGG with `adj_vec` outputs
    * [ ] Prediction of edge paths
* Discussion on hyperparameter optimisation
    * To optimise: model architecture parameters
    * Can tune on validation dataset if it's big enough, but test dataset is the 'right' one -- validation data however affects direction of training
    * Use metrics such as precision, AUC because we want to reduce the probability of false positives happening


## To-do (from last week [2022-03-08](unlisted/minutes/2022-03/2022-03-08.md))
* [x] Output filepaths for debugging  
* [x] 3rd network â€” batching method (`CombinatorialAdjNN`)
* [x] **Adjust validation DG** (ratio of edges to non-edges), resume training   
  ![](/unlisted/_img/training_comps.png)
* [ ] **Thesis**
* [x] [Thesis outline](unlisted/thesis-outline.md)
* [ ] Figure out how to reduce time taken for iterations in combinatorial prediction of $A$
* [ ] Increase num. neighbours right from the beginning, **try to get max. batch size possible**
* [ ] Hyperparameter optimisation of `EdgeNN`, e.g. include ReLU shifts
* For later/report
	* [ ] Comparison on test dataset
	* [ ] Get prediction times on model deployment
	* [ ] 3rd network Adj_vec method (`BruteForceAdjNN`), VGG16
	* [ ] Extraction of edge pixels for data generator, train a network to detect the edges pixels
* Low prio
	* [ ] Hyperparameter optimisation of `NodesNN`
	* [ ] Train first network (transfer learning)



## Current results
### $A$ prediction
Each iteration is over double the previous `num_neighbours`.

| $A$                        |
| -------------------------- |
| ![](/unlisted/_img/A0.png) |
| ![](/unlisted/_img/A1.png) |
| ![](/unlisted/_img/A2.png) |
| ![](/unlisted/_img/A3.png) | 

### Runtime
![](/unlisted/_img/adj_pred_runtime.png)  
These warnings could be due to the variable size of the tensors passed to the functions.

--> [Fixed](https://github.com/salehahr/tfgraph/commit/69fe2979ce0c5acd731210db524bf4bc5265389a)!

### Too many degrees detected
![](/unlisted/_img/schlimm.png)  
![](/unlisted/_img/schlimm2.png)

--> [Fixed](https://github.com/salehahr/tfgraph/commit/d52e0de12ff521064c8f21b0574d4b14e153c2d0)!