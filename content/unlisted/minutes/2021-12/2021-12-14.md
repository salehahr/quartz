---
title: 2021-12-14
date: 2021-12-10
aliases:
- /besprechung
tags:
  - -ma
---

## Agenda
### MA
* Besprochen letzte Woche:
	* scrap rotations as a data augmentation method
	* modify network architecture skel --> node attributes, e.g.
		* fewer convolution filters
		* filters between UNet final layer and the degrees and node types outputs
		* architecture that prioritises degrees and node types (because the node positions can be inferred from both)
	* for raw image --> filt/skel network, use pretrained weights for medical image processing tasks, modifications after the final unet layer
* [First run of model `20211210-102252\train`](unlisted/minutes/2021-12/2021-12-14-node-detection-model-first-run.md) with 64 filters
* ~~Second run with reduced num. of filters (16)~~
* Literature review

### HiWi
* ca. 60h left to work off! (8 full days)

### Other
* Literaturverzeichnis
* Aliases on Tuebingen computer



## To do (from last week) [2021-12-07](unlisted/minutes/2021-12/2021-12-07.md)
### HiWi
* [ ] One pane GUI
* [ ] Docs for Studienarbeit code (Kalman filter)  


### MA
* [x] Train model skeletonised -> node attributes using existing data
	* [x] Debug `DataGenerator`
	* [x] Debug NaN values
* [ ] Try out network variants for estimating skel --> node attributes
* [ ] Edge detection network with threading  
* [x] Literature research for dynamic problems (w.r.t. matrix dimensions)
* [ ] Data generation
	* [ ] Watch more videos and trim away bad sections
	* [ ] Adjust filter parameters so that more structures are visible


## [Notes](unlisted/minutes/2021-12/2021-12-14-notes.md)


## Reference
* [Correct implementation of `tf.data.Dataset`](https://stackoverflow.com/questions/48213766/split-a-dataset-created-by-tensorflow-dataset-api-in-to-train-and-test)  
	![](unlisted/_img/notes-tf-dataset.png)
	
## Outcomes
* Fastest to slowest convergence of the attributes (outputs):
	* Node positions (P)
	* Node degrees (D)
	* Node types (T)
* An idea: only train for D and T, get P which is implicitly encoded in the D and T matrices
	* Maybe not a good idea as P converges the fastest and probably helps D and T to converge.
* In the results for node degrees, D=2 is shown not to be classified correctly, probably because there are fewer cases where D=2
* Division of testing data sets:
	* Training DS: for training the network (model weights)
	* Validation DS: for validating the network, tuning hyperparameters, model parameters -- independent from training DS to enable gauging of overfit
	* Testing DS: for comparing different models (UNet, something else, etc.)
* Try out network variants for estimating skel --> node attributes (train with more data)
	1.  existing network as is (64f)
	2.  simplified network (in UNet structure) -- 16f, shallower NW, lower F + shallower NW
	3.  simplified network + more filters near the attribute outputs