---
title: mini-batch-gradient-descent
date: 2021-11-27
tags:
  - math
  - machine-learning
---

**Parent**: [Variations of gradient descent](ma/variations-gradient-descent.md)

**Source**: [google-ml-course](bibliography/google-ml-course.md)

# Mini-Batch Gradient Descent
* Performs gradient and loss calculation on [10 to 1000 data points](ma/batching-in-ml.md)
* Less noise compared to [SGD](ma/stochastic-gradient-descent.md)
* Nevertheless more efficient than full batch [gradient descent](ma/gradient-descent.md)