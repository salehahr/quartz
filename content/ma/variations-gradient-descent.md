---
title: variations-gradient-descent
date: 2021-11-27
tags:
  - math
  - machine-learning
---
**See also**: [Batching](ma/batching-in-ml.md)

**Source**: [google-ml-course](bibliography/google-ml-course.md)

# Variations of gradient descent

* The two extremes:
	* [Gradient descent ](ma/gradient-descent.md) 
		Batch = whole dataset
	* [Stochastic Gradient Descent (SGD) ](ma/stochastic-gradient-descent.md) 
		Batch = one data point
* The compromise: [Mini-Batch Gradient Descent](ma/mini-batch-gradient-descent.md)

For [neural networks](ma/neural-networks.md): [backpropagation](ma/backpropagation.md)